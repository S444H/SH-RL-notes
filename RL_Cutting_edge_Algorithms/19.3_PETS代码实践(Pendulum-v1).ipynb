{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 19.3 PETS代码实践(Pendulum-v1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1566c9b5b717af9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "导入相关库："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f74fe063306980d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# 基本库\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm  # 用于生成和操作截断正态分布（Truncated Normal Distribution）\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.smoothing import moving_average\n",
    "from utils.advantage import compute_advantage\n",
    "from utils.training import train_on_policy_agent\n",
    "# 神经网络\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# Gymnasium 是一个用于开发和测试强化学习算法的工具库，为 OpenAI Gym 的更新版本（2021迁移开发）\n",
    "import gymnasium as gym"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-22T04:21:38.766803400Z",
     "start_time": "2025-08-22T04:21:38.719333Z"
    }
   },
   "id": "2534e02a694511e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***候选动作序列的生成：交叉熵方法（CEM）：***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cf9e1f5b82c43c"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class CEM:  # 优化随机采样动作的分布的均值和方差\n",
    "    def __init__(self, n_sequence, elite_ratio, fake_env, upper_bound, lower_bound):\n",
    "        self.n_sequence = n_sequence\n",
    "        self.elite_ratio = elite_ratio  # 精英策略的比例（选择最好的前elite_ratio部分）\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        self.fake_env = fake_env  # 用来模拟环境的虚拟环境对象\n",
    "\n",
    "    def optimize(self, state, init_mean, init_var):\n",
    "        mean, var = init_mean, init_var  # 初始的动作分布的均值和方差，mean 控制动作的中心位置，var 控制动作的分散程度\n",
    "        X = truncnorm(-2, 2, loc=np.zeros_like(mean), scale=np.ones_like(var))  # 创建n维（动作维度）截断正态分布对象\n",
    "        state = np.tile(state, (self.n_sequence, 1))  # 扩展 n_sequence 个相同的状态，以便在同一时刻生成多个动作序列\n",
    "\n",
    "        for _ in range(5):  # 重复进行多次优化\n",
    "            lb_dist, ub_dist = mean - self.lower_bound, self.upper_bound - mean\n",
    "            constrained_var = np.minimum(np.minimum(np.square(lb_dist / 2), np.square(ub_dist / 2)), var)  # 方差的约束\n",
    "            # 生成动作序列\n",
    "            action_sequences = [X.rvs() for _ in range(self.n_sequence)] * np.sqrt(constrained_var) + mean\n",
    "            # 计算每条动作序列的累积奖励\n",
    "            returns = self.fake_env.propagate(state, action_sequences)[:, 0]\n",
    "            # 选取累积奖励高的若干条动作序列（精英序列）\n",
    "            elites = action_sequences[np.argsort(returns)][-int(self.elite_ratio * self.n_sequence):]\n",
    "            new_mean = np.mean(elites, axis=0)\n",
    "            new_var = np.var(elites, axis=0)\n",
    "            # 指数加权平均平滑更新更新动作序列分布\n",
    "            mean = 0.1 * mean + 0.9 * new_mean\n",
    "            var = 0.1 * var + 0.9 * new_var\n",
    "\n",
    "        return mean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-22T04:21:38.768308800Z",
     "start_time": "2025-08-22T04:21:38.729878600Z"
    }
   },
   "id": "f06399cdba95a3e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.定义模型中每一层的构造"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "404583cf6c68f5e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***激活函数定义：***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693877931069a48e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \"\"\" Swish激活函数 \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-22T04:21:38.804026800Z",
     "start_time": "2025-08-22T04:21:38.740307100Z"
    }
   },
   "id": "f125b9eddc8497db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Swish_ReLU_Sigmoid三个激活函数的曲线对比图](Illustrations/Swish_ReLU_Sigmoid三个激活函数的曲线对比图.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "650be9a8b8d1b535"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-22T04:21:38.805026700Z",
     "start_time": "2025-08-22T04:21:38.745736100Z"
    }
   },
   "id": "cc05fb34b78d9085"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***初始化网络层参数：***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf036cff15cdc15"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def init_weights(m):  # m 为某个网络层\n",
    "    \"\"\" 初始化模型权重 \"\"\"\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        \"\"\" 截断正态分布 \"\"\"\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)  # 用均值为 mean、标准差为 std 的正态分布随机数填充张量t \n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):  # 如果所有值都在范围内 (torch.sum(cond) == 0)，就退出循环\n",
    "                break\n",
    "            t = torch.where(\n",
    "                cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),mean=mean,std=std), \n",
    "                t)  # 如果有越界的值，就重新采样，并用 torch.where 把这些位置替换成新的采样值\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):  # 若 m 是全连接层（nn.Linear）或 自定义层 FCLayer\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))  # 权重 m.weight 用截断正态分布初始化\n",
    "        m.bias.data.fill_(0.0)  # 偏置 m.bias 全部设为 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-22T04:21:38.806029300Z",
     "start_time": "2025-08-22T04:21:38.753448700Z"
    }
   },
   "id": "3e8009e0975c5f46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "> 标准差缩放技巧，保证方差不会太大：\n",
    "$$\\mathrm{std}=\\frac{1}{2\\sqrt{m-inputdim}}$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4b6c9ff58cb05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***自定义的全连接层：***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f3f73b60a9355d"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    \"\"\" 自定义的全连接层 (FCLayer)，支持 ensemble（集成） \"\"\"\n",
    "    # ensemble_size: 集成的个数（即同时训练多少组独立的参数）\n",
    "    # activation: 激活函数（如 ReLU、Swish）\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(\n",
    "            torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))  # 矩阵计算\n",
    "            # X:(ensemble_size, batch_size, input_dim)\n",
    "            # W:(ensemble_size, input_dim, output_dim)\n",
    "            # 偏置bias扩展到 (ensemble_size, batch_size, output_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-22T04:21:38.806029300Z",
     "start_time": "2025-08-22T04:21:38.761485900Z"
    }
   },
   "id": "5647aa658ac5c2bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.环境模型集成"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7b0be2de164e6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***softplus 函数：***\n",
    "$$\\mathrm{softplus}(x)=\\log(1+e^x)$$\n",
    "- **softplus** 常用于 **平滑 和 数值约束**\n",
    "- 相比直接 clamp()，**softplus** **可导且更平滑**，不会破坏训练梯度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d82efd931a0cd5ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\" 环境模型集成 \"\"\"\n",
    "    def __init__(self,\n",
    "                 state_dim,\n",
    "                 action_dim,\n",
    "                 ensemble_size=5,  # 模型成员总数为ensemble_size，对应训练ensemble_size组权重\n",
    "                 learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self._output_dim = (state_dim + 1) * 2  # 预测状态与奖励以及对应方差\n",
    "        # 方差上界和下界\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),\n",
    "                                        requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),\n",
    "                                        requires_grad=False)\n",
    "        # 集成模型中每个成员为5层神经网络\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size, Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size, nn.Identity())  # nn.Identity()，原样返回输入\n",
    "        self.apply(init_weights)  # 对所有 nn.Linear 和 FCLayer 层做权重初始化\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):  # 选择是否返回对数方差\n",
    "        # 前向传播\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        # 输出一分为二\n",
    "        mean   = ret[:, :, :self._output_dim // 2]   # 前一半 -> 均值\n",
    "        raw_lv = ret[:, :, self._output_dim // 2:]   # 后一半 -> 原始对数方差 logvar（未约束）\n",
    "        # 使用softplus函数,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(self._max_logvar - raw_lv)\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):  # 是否选择带方差的 loss\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            # 对应简化损失函数\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) * inverse_var,\n",
    "                                             dim=-1),dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            # \n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss += 0.01 * torch.sum(self._max_logvar) - 0.01 * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "241f5dcb0181bf31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
