{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1566c9b5b717af9b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 19.3 PETS代码实践(Pendulum-v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fe063306980d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "导入相关库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2534e02a694511e5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-25T07:33:00.897762900Z",
     "start_time": "2025-08-25T07:33:00.889316100Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基本库\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm  # 用于生成和操作截断正态分布（Truncated Normal Distribution）\n",
    "import itertools  # 生成迭代器和组合、排列等高效遍历操作\n",
    "import collections\n",
    "\n",
    "# 神经网络\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# Gymnasium 是一个用于开发和测试强化学习算法的工具库，为 OpenAI Gym 的更新版本（2021迁移开发）\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9e1f5b82c43c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***候选动作序列的生成：交叉熵方法（CEM）：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06399cdba95a3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.818386700Z",
     "start_time": "2025-08-22T13:44:36.812874200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CEM:  # 优化随机采样动作的分布的均值和方差\n",
    "    def __init__(self, n_sequence, elite_ratio, fake_env, upper_bound, lower_bound):\n",
    "        self.n_sequence = n_sequence  # 生成的动作序列数量\n",
    "        self.elite_ratio = elite_ratio  # 精英策略的比例（选择最好的前elite_ratio部分）\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        self.fake_env = fake_env  # 用来模拟环境的虚拟环境对象\n",
    "\n",
    "    def optimize(self, state, init_mean, init_var):\n",
    "        mean, var = init_mean, init_var  # 初始动作分布\n",
    "        X = truncnorm(-2, 2, loc=np.zeros_like(mean), scale=np.ones_like(var))  # 创建n维（动作维度）截断正态分布对象\n",
    "        state = np.tile(state, (self.n_sequence, 1))  # 扩展 n_sequence 个相同的状态，对应多个动作序列\n",
    "\n",
    "        for _ in range(5):  # 重复进行多次优化\n",
    "            lb_dist, ub_dist = mean - self.lower_bound, self.upper_bound - mean\n",
    "            constrained_var = np.minimum(np.minimum(np.square(lb_dist / 2), np.square(ub_dist / 2)), var)  # 方差的约束\n",
    "            # 生成动作序列(n_sequence，act_dim*plan_horizon)\n",
    "            action_sequences = [X.rvs() for _ in range(self.n_sequence)] * np.sqrt(constrained_var) + mean\n",
    "            # 计算每条动作序列的累积奖励\n",
    "            returns = self.fake_env.propagate(state, action_sequences)[:, 0]\n",
    "            # 选取累积奖励高的若干条动作序列（精英序列）\n",
    "            elites = action_sequences[np.argsort(returns)][-int(self.elite_ratio * self.n_sequence):]\n",
    "            new_mean = np.mean(elites, axis=0)\n",
    "            new_var = np.var(elites, axis=0)\n",
    "            # 指数加权平均平滑更新动作序列分布\n",
    "            mean = 0.1 * mean + 0.9 * new_mean\n",
    "            var = 0.1 * var + 0.9 * new_var\n",
    "\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f3352e040d5c27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.855289500Z",
     "start_time": "2025-08-22T13:44:36.821386400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内容: [0.5 0.5]\n",
      "形状: (2,)\n",
      "内容: [array([0.21312777, 0.16434273]), array([-0.1878664 , -0.17877162])]\n",
      "形状: (2, 2)\n",
      "内容: tensor([[ 0.2131],\n",
      "        [-0.1879]], dtype=torch.float64)\n",
      "形状: torch.Size([2, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86191\\AppData\\Local\\Temp\\ipykernel_24680\\4165825641.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  actions = torch.as_tensor(action_sequences)\n"
     ]
    }
   ],
   "source": [
    "# 模拟 CEM 中的参数\n",
    "n_sequence = 2\n",
    "action_dim = 3\n",
    "mean = np.array([0.5])\n",
    "var = np.array([0.1])\n",
    "\n",
    "# 单条动作序列长度控制\n",
    "mean = np.tile(mean,2)\n",
    "print(\"内容:\", mean)\n",
    "print(\"形状:\", np.array(mean).shape)\n",
    "\n",
    "# 截断正态分布对象\n",
    "X = truncnorm(-2, 2, loc=np.zeros_like(mean), scale=np.ones_like(var))\n",
    "\n",
    "# 生成动作序列\n",
    "action_sequences = [X.rvs() for _ in range(n_sequence)]\n",
    "print(\"内容:\", action_sequences)\n",
    "print(\"形状:\", np.array(action_sequences).shape)\n",
    "\n",
    "actions = torch.as_tensor(action_sequences)\n",
    "action = torch.unsqueeze(actions[:, 0], 1)\n",
    "print(\"内容:\", action)\n",
    "print(\"形状:\", action.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16cb97252316041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.858815400Z",
     "start_time": "2025-08-22T13:44:36.842582300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内容: [ 0.73121476 -0.6821473  -0.25939333]\n",
      "形状: (3,)\n",
      "内容: [[ 0.73121476 -0.6821473  -0.25939333]\n",
      " [ 0.73121476 -0.6821473  -0.25939333]]\n",
      "形状: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "env_name = 'Pendulum-v1'\n",
    "env = gym.make(env_name)\n",
    "state, info = env.reset()\n",
    "\n",
    "print(\"内容:\", state)\n",
    "print(\"形状:\", np.array(state).shape)\n",
    "state = np.tile(state, (n_sequence, 1))\n",
    "print(\"内容:\", state)\n",
    "print(\"形状:\", np.array(state).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404583cf6c68f5e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.环境模型中每一层的构造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693877931069a48e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***激活函数定义：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f125b9eddc8497db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.868304700Z",
     "start_time": "2025-08-22T13:44:36.857813900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \"\"\" Swish激活函数 \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650be9a8b8d1b535",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Swish_ReLU_Sigmoid三个激活函数的曲线对比图](Illustrations/Swish_ReLU_Sigmoid三个激活函数的曲线对比图.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc05fb34b78d9085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.949359600Z",
     "start_time": "2025-08-22T13:44:36.865788400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf036cff15cdc15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***初始化网络层参数：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8009e0975c5f46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.970852300Z",
     "start_time": "2025-08-22T13:44:36.910072300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_weights(m):  # m 为某个网络层\n",
    "    \"\"\" 初始化模型权重 \"\"\"\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        \"\"\" 截断正态分布 \"\"\"\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)  # 用均值为 mean、标准差为 std 的正态分布随机数填充张量t \n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):  # 如果所有值都在范围内 (torch.sum(cond) == 0)，就退出循环\n",
    "                break\n",
    "            t = torch.where(\n",
    "                cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),mean=mean,std=std), \n",
    "                t)  # 如果有越界的值，就重新采样，并用 torch.where 把这些位置替换成新的采样值\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):  # 若 m 是全连接层（nn.Linear）或 自定义层 FCLayer\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))  # 权重 m.weight 用截断正态分布初始化\n",
    "        m.bias.data.fill_(0.0)  # 偏置 m.bias 全部设为 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b6c9ff58cb05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 标准差缩放技巧，保证方差不会太大：\n",
    "$$\\mathrm{std}=\\frac{1}{2\\sqrt{m-inputdim}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3f73b60a9355d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***自定义的全连接层：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5647aa658ac5c2bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.970852300Z",
     "start_time": "2025-08-22T13:44:36.918756500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    \"\"\" 自定义的全连接层 (FCLayer)，支持 ensemble（集成） \"\"\"\n",
    "    # ensemble_size: 集成的个数（即同时训练多少组独立的参数）\n",
    "    # activation: 激活函数（如 ReLU、Swish）\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(\n",
    "            torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))  # 矩阵计算\n",
    "            # X:(ensemble_size, batch_size, input_dim)\n",
    "            # W:(ensemble_size, input_dim, output_dim)\n",
    "            # 偏置bias扩展到 (ensemble_size, batch_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b0be2de164e6f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.集成环境模型设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82efd931a0cd5ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***softplus 函数：***\n",
    "$$\\mathrm{softplus}(x)=\\log(1+e^x)$$\n",
    "- **softplus** 常用于 **平滑 和 数值约束**\n",
    "- 相比直接 clamp()，**softplus** **可导且更平滑**，不会破坏训练梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241f5dcb0181bf31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.971852500Z",
     "start_time": "2025-08-22T13:44:36.930623800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\" 环境模型集成 \"\"\"\n",
    "    def __init__(self,\n",
    "                 state_dim,\n",
    "                 action_dim,\n",
    "                 ensemble_size=5,  # 模型成员总数为ensemble_size，对应训练ensemble_size组权重\n",
    "                 learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self._output_dim = (state_dim + 1) * 2  # 预测奖励与状态增量 以及 对应方差\n",
    "        # 方差上界和下界\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),\n",
    "                                        requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),\n",
    "                                        requires_grad=False)\n",
    "        # 集成模型中每个成员为5层神经网络\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size, Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size, nn.Identity())  # nn.Identity()，原样返回输入\n",
    "        self.apply(init_weights)  # 对所有 nn.Linear 和 FCLayer 层做权重初始化\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):  # 选择是否返回对数方差\n",
    "        # 前向传播\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        # 输出一分为二\n",
    "        mean   = ret[:, :, :self._output_dim // 2]   # 前一半 -> 均值\n",
    "        raw_lv = ret[:, :, self._output_dim // 2:]   # 后一半 -> 原始对数方差 logvar（未约束）\n",
    "        # 使用softplus函数,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(self._max_logvar - raw_lv)\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):  # 是否选择带方差的 loss\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            # 对应简化损失函数\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) * inverse_var,\n",
    "                                             dim=-1),dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            # 退化为普通的 MSE\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train_my(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        # 惩罚 _max_logvar 太大；惩罚 _min_logvar 太小\n",
    "        loss += 0.01 * torch.sum(self._max_logvar) - 0.01 * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb08058bbc385a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***预测模型的训练：***\n",
    "- 独立的训练顺序\n",
    "- Mini-batch 训练\n",
    "- 验证集评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92021a7ceca694d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.973233100Z",
     "start_time": "2025-08-22T13:44:36.950359600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnsembleDynamicsModel:\n",
    "    def __init__(self, state_dim, action_dim, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim,\n",
    "                                   action_dim,\n",
    "                                   ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0  # 在 5 次没有获得表现提升时就结束训练\n",
    "        # 记录每个网络的最佳 epoch 和对应验证集损失，用于早停和选择最优模型\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "    # 模型成员并行训练\n",
    "    def train(self,\n",
    "              inputs,\n",
    "              labels,\n",
    "              batch_size=64,\n",
    "              holdout_ratio=0.1,\n",
    "              max_iter=20):\n",
    "        # 设置训练集与验证集，holdout_ratio 默认为 0.1，即 10% 数据用于验证\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        \n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]  # 训练集：90%\n",
    "        holdout_inputs, holdout_labels = inputs[:num_holdout], labels[:num_holdout]  # 验证集：10%\n",
    "        # 复制验证集数据，使每个网络都能独立计算损失\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat([self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat([self._num_network, 1, 1])\n",
    "\n",
    "        # itertools.count() 会无限产生整数：0,1,2,… ；实际训练结束条件在循环内部通过 _save_best 和 epoch > max_iter 来控制\n",
    "        for epoch in itertools.count():  # itertools.count() 会无限产生整数：0,1,2,…\n",
    "            # 为每个模型成员生成独立的训练顺序（认知不确定性）\n",
    "            train_index = np.vstack([\n",
    "                np.random.permutation(train_inputs.shape[0])\n",
    "                for _ in range(self._num_network)\n",
    "            ])\n",
    "            # Mini-batch 训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):  # 按 batch_size 分块，逐个 batch 进行训练\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos +batch_size]\n",
    "                train_input = torch.from_numpy(train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(train_labels[batch_index]).float().to(device)\n",
    "\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train_my(loss)\n",
    "                \n",
    "            # 用验证集评估 Mini-batch训练后 模型的性能\n",
    "            with torch.no_grad():  # 在其作用域内禁止梯度计算\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean,\n",
    "                                                    logvar,\n",
    "                                                    holdout_labels,\n",
    "                                                    use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()  # GPU 张量不能直接用于大多数 Python 操作\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False  # 标记本轮是否有网络取得了显著改进\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):  # 一次最大按 batch_size 预测，避免一次性占用过多显存\n",
    "        mean, var = [], []\n",
    "        for i in range(0, inputs.shape[0], batch_size):\n",
    "            input = torch.from_numpy(inputs[i:min(i + batch_size, inputs.shape[0])]).float().to(device)\n",
    "            # 用训练好的模型预测\n",
    "            cur_mean, cur_var = self.model(input[None, :, :].repeat([self._num_network, 1, 1]), return_log_var=False)\n",
    "            mean.append(cur_mean.detach().cpu().numpy())\n",
    "            var.append(cur_var.detach().cpu().numpy())\n",
    "        return np.hstack(mean), np.hstack(var)  # (num_network, total_samples, mean)，(num_network, total_samples, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e8d1a6ccbd36f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***定义模拟环境 FakeEnv，用训练好的 EnsembleDynamicsModel 来预测下一状态和奖励：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec38e87731bc6b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:36.974245700Z",
     "start_time": "2025-08-22T13:44:36.961821900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)  \n",
    "        # (num_network, n_states, mean)\n",
    "        ensemble_model_means[:, :, 1:] += obs.numpy()  # 当前状态+预测的状态增量，变为下一状态\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        # 得出每个模型成员的预测结果并使用高斯采样\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(\n",
    "            size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        # 为每一个状态的下一步预测使用随机的模型成员\n",
    "        models_to_use = np.random.choice([i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        # batch_size中每个状态都随机采用了某个模型成员进行预测（相应的奖励以及下一个状态）\n",
    "        rewards, next_obs = samples[:, :1], samples[:, 1:]\n",
    "        return rewards, next_obs\n",
    "\n",
    "    def propagate(self, obs, actions):\n",
    "        with torch.no_grad():\n",
    "            obs = np.copy(obs)  # (n_sequence, state_dim)\n",
    "            total_reward = np.expand_dims(np.zeros(obs.shape[0]), axis=-1)\n",
    "            obs, actions = torch.as_tensor(obs), torch.as_tensor(actions)\n",
    "            for i in range(actions.shape[1]):  # 生成的候选动作序列的长度\n",
    "                action = torch.unsqueeze(actions[:, i], 1)  # 取每个生成序列中的第i个动作，并增加一个新维度，对齐状态obs\n",
    "                rewards, next_obs = self.step(obs, action)\n",
    "                total_reward += rewards\n",
    "                obs = torch.as_tensor(next_obs)\n",
    "            return total_reward  # 返回每条生成序列的总价值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53cef2e145ce8d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***定义经验回放池Replay Buffer：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e5bc2e091448d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-25T07:33:08.158767100Z",
     "start_time": "2025-08-25T07:33:08.126213800Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffd43fe171ef27",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3. PETS 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af3f2bb21477e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:37.028715Z",
     "start_time": "2025-08-22T13:44:36.975998800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PETS:\n",
    "    \"\"\" PETS算法(Pendulum-v1) \"\"\"\n",
    "    def __init__(self, env, replay_buffer, n_sequence, elite_ratio,\n",
    "                 plan_horizon, num_episodes):\n",
    "        # 真实环境\n",
    "        self._env = env\n",
    "        self._env_pool = replay_buffer\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        self._action_dim = env.action_space.shape[0]\n",
    "        self.upper_bound = env.action_space.high[0]\n",
    "        self.lower_bound = env.action_space.low[0]\n",
    "        # 环境模型\n",
    "        self._model = EnsembleDynamicsModel(obs_dim, self._action_dim)\n",
    "        self._fake_env = FakeEnv(self._model)\n",
    "        self._cem = CEM(n_sequence, elite_ratio, self._fake_env, self.upper_bound, self.lower_bound)\n",
    "        \n",
    "        self.plan_horizon = plan_horizon\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    def train_model(self):\n",
    "        env_samples = self._env_pool.return_all_samples()\n",
    "        obs = env_samples[0]\n",
    "        actions = np.array(env_samples[1])\n",
    "        rewards = np.array(env_samples[2]).reshape(-1, 1)\n",
    "        next_obs = env_samples[3]\n",
    "        inputs = np.concatenate((obs, actions), axis=-1)\n",
    "        labels = np.concatenate((rewards, next_obs - obs), axis=-1)\n",
    "        self._model.train(inputs, labels)\n",
    "\n",
    "    def mpc(self):\n",
    "        mean = np.tile((self.upper_bound + self.lower_bound) / 2.0, self.plan_horizon)\n",
    "        var = np.tile(np.square(self.upper_bound - self.lower_bound) / 16, self.plan_horizon)\n",
    "        obs, info = self._env.reset()\n",
    "        done, episode_return = False, 0\n",
    "        truncated = False\n",
    "        while not (done or truncated):\n",
    "            actions = self._cem.optimize(obs, mean, var)  # 优化后的候选动作序列\n",
    "            action = actions[:self._action_dim]  # 选取第一个动作\n",
    "            next_obs, reward, done, truncated, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "            mean = np.concatenate([\n",
    "                np.copy(actions)[self._action_dim:],\n",
    "                np.zeros(self._action_dim)\n",
    "            ])  # 用于多次优化\n",
    "        return episode_return\n",
    "\n",
    "    def explore(self):\n",
    "        obs, info = self._env.reset()\n",
    "        done, episode_return = False, 0\n",
    "        truncated = False\n",
    "        while not (done or truncated):\n",
    "            action = self._env.action_space.sample()\n",
    "            next_obs, reward, done, truncated, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 先进行随机策略的探索来收集一条序列的数据\n",
    "        print('episode: 1, 初始随机动作采样return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episodes - 1):\n",
    "            self.train_model()  # 每次迭代先对环境模型进行训练\n",
    "            episode_return = self.mpc()  # 然后在环境模型的指导下选择动作，并计算指导序列的回报\n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a6d7312155a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b4c4a11b0143710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:55:32.121944100Z",
     "start_time": "2025-08-22T13:44:36.992676300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, 初始随机动作采样return: -1176\n",
      "episode: 2, return: -888\n",
      "episode: 3, return: -1427\n",
      "episode: 4, return: -1046\n",
      "episode: 5, return: -1245\n",
      "episode: 6, return: -1050\n",
      "episode: 7, return: -267\n",
      "episode: 8, return: -124\n",
      "episode: 9, return: -257\n",
      "episode: 10, return: -381\n"
     ]
    }
   ],
   "source": [
    "n_sequence = 50\n",
    "elite_ratio = 0.2\n",
    "plan_horizon = 25\n",
    "num_episodes = 10\n",
    "\n",
    "buffer_size = 100000\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "pets = PETS(env, replay_buffer, n_sequence, elite_ratio, plan_horizon, num_episodes)\n",
    "\n",
    "return_list = pets.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd879840dc646ccf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5.效果绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebc0c6b3b63d1764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:55:32.133490200Z",
     "start_time": "2025-08-22T13:55:32.119941800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "episodes_list = list(range(len(return_list)))\n",
    "# 创建 DataFrame\n",
    "df1 = pd.DataFrame({'Episodes': episodes_list, 'Returns': return_list})\n",
    "# 保存为 CSV 文件\n",
    "df1.to_csv('PETS_Pendulum-v1_returns_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "id": "78496185139ca89e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T10:28:31.181755Z",
     "start_time": "2025-09-25T10:28:30.658275Z"
    }
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/PETS_Pendulum-v1_returns_data.csv')  # 从 CSV 文件中读取数据\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['Episodes'], y=df['Returns'], mode='lines', name='Returns'))\n",
    "fig.update_layout(\n",
    "    title='PETS on Pendulum-v1',\n",
    "    xaxis_title='Episodes',\n",
    "    yaxis_title='Returns',\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Returns",
         "x": {
          "dtype": "i1",
          "bdata": "AAECAwQFBgcICQ=="
         },
         "y": {
          "dtype": "f8",
          "bdata": "YbJKwkBgksDcEsxoJcSLwEEaymdDTpbA7MrPO9xakMDWgAEGdnSTwICWR8m3apDAls2maZq5cMDsDC8wExlfwHyOuFJMGXDAC46VJSjUd8A="
         },
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "PETS on Pendulum-v1"
        },
        "xaxis": {
         "title": {
          "text": "Episodes"
         }
        },
        "yaxis": {
         "title": {
          "text": "Returns"
         }
        },
        "showlegend": true
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "ed2df1ab189b73fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "虽然每次选取动作都需要在环境模型上进行大量的模拟，运行速度慢\n",
    "但 **PETS** 算法提高了样本效率，在与 **环境交互次数少得多** 的情况下就取得了与 **SAC** 算法的差不多的效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
