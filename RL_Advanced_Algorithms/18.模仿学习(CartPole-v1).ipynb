{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b524eb201dc3aee7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 18.模仿学习（Imitation Learning，简称IL）\n",
    "> 虽然 **强化学习** 不需要有监督学习中的标签数据，但它十分依赖 **奖励函数** 的设置。有时在 **奖励函数** 上做一些微小的改动，训练出来的策略就会有天差地别。而且在现实场景中， **奖励信号** 总是难以明确：\n",
    "- 例如，对于无人驾驶车辆智能体的规控，其观测是当前的环境感知恢复的 3D 局部环境，动作是车辆接下来数秒的具体路径规划，那么奖励是什么？如果只是规定正常行驶而不发生碰撞的奖励为+1，发生碰撞为-100，那么智能体学习的结果则很可能是找个地方停滞不前。**奖励函数** 往往需要精心设计和调试。\n",
    "> 那有什么方法可以跳过 **奖励函数** 的设计呢？\n",
    "\n",
    "> **模仿学习** 研究的便是这一类问题，在模仿学习的框架下，存在 **专家智能体**，其在某个环境下提供的一系列 **状态动作对**，被认为是 **最优行为策略**。**模仿者**的任务则是利用这些 **专家数据** 进行训练，**无须奖励信号** 就可以达到一个接近专家的策略。\n",
    "> 学术界关于 **模仿学习** 的传统核心方法分为 **3 类**：\n",
    "\n",
    "| 方法                                                            | 概念                                                                                           | 缺点                      | 适用任务                                 | 最早时间 | 论文链接                                                                                                     |\n",
    "|---------------------------------------------------------------|----------------------------------------------------------------------------------------------|-------------------------|--------------------------------------|------|----------------------------------------------------------------------------------------------------------|\n",
    "| **行为克隆（behavior cloning，BC）**                                 | 通过监督学习模仿专家的状态-动作对，直接复制专家的行为                                                                  | - 缺乏长期奖励优化<br> - 数据依赖性强 | 数据充足且专家行为完美的任务，如机器人抓取、路径规划等          | 1988 | [论文学习](https://papers.neurips.cc/paper_files/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf) |\n",
    "| **逆强化学习（inverse RL）**                                         | 不同于行为克隆仅仅是复制专家的动作，它的目标是从专家的行为中推断出奖励函数。通过推断奖励函数，智能体就可以基于奖励来优化自己的策略了                           | - 计算复杂度高<br> - 数据需求大    | 无法直接获取奖励信号或奖励函数难以设计的任务，如自主驾驶、复杂策略规划。 | 2000 | [论文学习](https://www.cl.cam.ac.uk/~ey204/teaching/ACS/R244_2022_2023/papers/NG_ICML_2000.pdf)              |\n",
    "| **生成式对抗模仿学习（generative adversarial imitation learning，GAIL）** | 结合生成对抗网络（GANs）将模仿学习视为一个对抗过程，其中一个生成器（模仿者）试图模仿专家的行为，另一个判别器（判别器）则尝试判断动作是否来自专家。最终，生成器学会如何模仿专家的策略 | - 训练不稳定<br> - 对样本质量敏感   | 没有明确奖励信号的复杂任务，如机器人运动、视频游戏AI等。        | 2016 | [论文学习](https://arxiv.org/abs/1606.03476)                                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9f40f2bda35ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 本节主要介绍 **行为克隆** 和 **生成式对抗模仿学习**\n",
    "> **逆强化学习** 有良好的学术贡献，但由于其计算复杂度较高，实际应用的价值较小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31feca806a33ccfd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 18.1 行为克隆\n",
    "> **行为克隆（BC）** 直接使用 **监督学习** 方法：\n",
    "$$\\theta^*=\\arg\\min_\\theta\\mathbb{E}_{(s,a)\\sim B}[\\mathcal{L}(\\pi_\\theta(s),a)]$$\n",
    "- $B$是专家的数据集，$\\mathcal{L}$是对应监督学习框架下的损失函数\n",
    "- 若动作是离散的，该损失函数可以是最大似然估计得到的；若动作是连续的，该损失函数可以是均方误差函数\n",
    "> 但也造成了其存在很大的局限性：由于训练使用的 **专家数据** 难以囊括所有状态分布，因此 BC 只能在专家数据的状态分布下预测得比较准。而且，**强化学习** 面对的是一个序贯决策问题，只要存在一点偏差，就有可能导致下一个遇到的状态是在专家数据中没有见过的。此时，由于没有在此状态（或者比较相近的状态）下训练过，策略可能就会随机选择一个动作，这会导致下一个状态 **进一步偏离** 专家策略遇到的的数据分布。最终，该策略在真实环境下不能得到比较好的效果，这被称为行为克隆的 **复合误差（compounding error）** 问题：\n",
    "![行为克隆带来的复合误差问题](Illustrations/行为克隆带来的复合误差问题.png)\n",
    "> 即使 **行为克隆** 有这些局限，但其实现十分简单，因此在很多实际场景下它都可以作为 **策略预训练** 的方法：使 **策略** 无须在 **最开始低效地** 通过和环境交互来探索较好的动作，而是通过模仿专家智能体的行为数据来 **快速达到较高水平**，为接下来的强化学习创造一个 **高起点**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f664ac5ccf9ec8dd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 18.2 生成式对抗模仿学习\n",
    "> **生成式对抗模仿学习** 是2016年由斯坦福大学研究团队提出的 **基于生成式对抗网络** 的**模仿学习**，它诠释了**生成式对抗网络**的 **本质** 其实就是**模仿学习**\n",
    "> **GAIL** 算法中有一个 **判别器** 和一个 **策略**：\n",
    "- **策略** 就相当于是生成式对抗网络中的 **生成器（generator）**，给定一个状态，**策略** 会输出这个状态下应该采取的动作\n",
    "- **判别器（discriminator）$D_\\phi$** 将状态动作对$(s,a)$作为输入，输出一个 0 到 1 之间的实数，表示 **判别器** 认为该状态动作对来自 **智能体策略$\\theta$** 而非 **专家$E$** 的概率。**判别器** 的目标是尽量将专家数据的输出靠近 0，将模仿者策略的输出靠近 1，这样就可以 **将两组数据分辨开**。\n",
    "\n",
    "> 于是**判别器$D_\\phi$** 的目标是最大化对数似然：\n",
    "$$\\mathcal{L}_D(\\phi)=\\mathbb{E}_{(s,a)\\sim\\pi_\\theta}[\\log D_\\phi(s,a)]+\\mathbb{E}_{(s,a)\\sim\\pi_E}[\\log(1-D_\\phi(s,a))]$$\n",
    "\n",
    "> 实际训练时，取负，最小化 **损失函数（Binary Cross-Entropy Loss for Discriminator）**：\n",
    "$$\\min_\\phi-\\mathcal{L}_D(\\phi)=-\\mathbb{E}_{(s,a)\\sim\\pi_\\theta}[\\log D_\\phi(s,a)]-\\mathbb{E}_{(s,a)\\sim\\pi_E}[\\log(1-D_\\phi(s,a))]$$\n",
    "\n",
    "> 本质上为 **二分类交叉熵损失 BCELoss（Binary Cross-Entropy Loss）**，依据**真实采样分布**计算与**预测分布**的差异：\n",
    "$$\\mathrm{BCE}(p,y)=-\\left(y\\cdot\\log(p)+(1-y)\\cdot\\log(1-p)\\right)$$\n",
    "\n",
    "> 有了 **判别器$D_\\phi$** 之后，**策略** 的目标就是其交互产生的轨迹能被 **判别器** 误认为专家轨迹，所以将 **判别器的输出** 作为 **奖励函数** 来训练 **模拟者的策略**：\n",
    "$$r(s,a)=-\\log D(s,a)$$\n",
    "\n",
    "- **在不断的对抗过程中**：训练初期，**判别器**能够轻易区分专家数据和策略数据，因而对专家样本输出接近 0、对策略样本输出接近 1；随着**策略**不断更新以获得更高奖励，它会逐渐生成更接近专家的数据分布，使得**判别器**的区分难度增大，输出趋于模糊；在理论上的收敛点（**纳什均衡**）时，**策略分布与专家分布**完全一致，**判别器**无法再区分二者，只能对所有样本给出约 0.5 的概率，从而体现出博弈的平衡。\n",
    "\n",
    "> 可见，**GAIL** 中的 **策略** 需要和环境进行交互，这一点和 **BC** 不同，**BC** 完全不需要和环境交互\n",
    "> **GAIL** 实质上是模仿了 **专家策略的占用度量**，即 **尽量使得** 在环境中 **策略的占用度量$\\rho_{\\pi}(s,a)$** 和 **专家策略的占用度量$\\rho_{E}(s,a)$** 一致：\n",
    "![GAIL的优化目标](Illustrations/GAIL的优化目标.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc7f3dd148e14a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 18.3 代码实践（CartPole-v1）\n",
    "- 生成专家数据\n",
    "- **行为克隆** 算法实现\n",
    "- **生成式对抗模仿学习** 算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137cb5be58db81c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "导入相关库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a88b89b940a745ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T13:46:02.883386600Z",
     "start_time": "2025-08-18T13:46:02.868318600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 基本库\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.smoothing import moving_average\n",
    "from utils.advantage import compute_advantage\n",
    "from utils.training import train_on_policy_agent\n",
    "# 神经网络\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# Gymnasium 是一个用于开发和测试强化学习算法的工具库，为 OpenAI Gym 的更新版本（2021迁移开发）\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba12fe8756579",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 生成专家数据：\n",
    "> 通过 **PPO** 算法训练出一个表现良好的专家模型，再利用专家模型生成专家数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1953dccc08298949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T12:32:08.384592300Z",
     "start_time": "2025-08-18T12:32:08.281495500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "\n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "class PPO:\n",
    "    \"\"\" PPO-Clip（离散动作） \"\"\"\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda, epochs, eps, gamma, device):\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.critic = ValueNet(state_dim, hidden_dim).to(device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.lmbda = lmbda\n",
    "        self.epochs = epochs   # 一条序列的数据用来训练 epochs 轮\n",
    "        self.eps = eps         # PPO-Clip 的范围参数\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor(np.array([state]), dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states_np = np.array(transition_dict['states'])  # 转换成统一的大 np.ndarray，PyTorch更高效处理\n",
    "        states = torch.tensor(states_np, dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states_np = np.array(transition_dict['next_states'])  # 转换成统一的大 np.ndarray，PyTorch更高效处理\n",
    "        next_states = torch.tensor(next_states_np, dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        \n",
    "        td_target = rewards + self.gamma * self.critic(next_states) * (1 - dones)  # 时序差分目标\n",
    "        td_delta = td_target - self.critic(states)                                 # 时序差分误差\n",
    "        advantage = compute_advantage(self.gamma, self.lmbda, td_delta.cpu()).to(self.device)\n",
    "        \n",
    "        old_log_probs = torch.log(self.actor(states).gather(1,actions)).detach()\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            log_probs = torch.log(self.actor(states).gather(1, actions))\n",
    "            ratio = torch.exp(log_probs - old_log_probs)\n",
    "            \n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1 - self.eps, 1 + self.eps) * advantage  # Clip\n",
    "            \n",
    "            actor_loss = torch.mean(-torch.min(surr1, surr2))  # PPO 损失函数\n",
    "            critic_loss = torch.mean(F.mse_loss(self.critic(states), td_target.detach()))\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            critic_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.critic_optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaff4af9013b45f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T12:32:08.415589500Z",
     "start_time": "2025-08-18T12:32:08.291563500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment spec: EnvSpec(id='CartPole-v1', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, disable_env_checker=False, kwargs={}, namespace=None, name='CartPole', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv')\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)    # 设置 NumPy 的随机种子\n",
    "torch.manual_seed(0) # 设置 PyTorch CPU 随机种子\n",
    "torch.cuda.manual_seed_all(0) # 设置 PyTorch GPU 随机种子, 由于GPU并行性, 只能极大减小偏差\n",
    "\n",
    "env = gym.make('CartPole-v1')  # CartPole-v1 最大回合步数修改到了500步(v0为200)\n",
    "#env = env.unwrapped # 获取原始环境（绕过 TimeLimit 包装器）解除最大步数500限制\n",
    "env.reset(seed=0)   # 环境通常依赖于其他随机数生成器来初始化状态、进行探索(推荐位于以上随机之后)\n",
    "print(\"Environment spec:\", env.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3494c1482315205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T12:32:11.484486600Z",
     "start_time": "2025-08-18T12:32:08.312077Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "hidden_dim = 128\n",
    "\n",
    "lmbda = 0.95\n",
    "eps = 0.2\n",
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-2\n",
    "gamma = 0.98\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device( \"cpu\")\n",
    "agent = PPO(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda,\n",
    "            epochs, eps, gamma, device)\n",
    "num_episodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b0fbdd37465bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T12:38:08.993383800Z",
     "start_time": "2025-08-18T12:32:11.486487600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0: 100%|██████████| 50/50 [00:12<00:00,  4.08it/s, episode=50, return=269.300]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:27<00:00,  1.80it/s, episode=100, return=397.900]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:24<00:00,  2.07it/s, episode=150, return=177.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:39<00:00,  1.26it/s, episode=200, return=500.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:41<00:00,  1.21it/s, episode=250, return=500.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:42<00:00,  1.19it/s, episode=300, return=500.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:42<00:00,  1.17it/s, episode=350, return=500.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:45<00:00,  1.10it/s, episode=400, return=500.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s, episode=450, return=500.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:40<00:00,  1.23it/s, episode=500, return=500.000]\n"
     ]
    }
   ],
   "source": [
    "return_list = train_on_policy_agent(env, agent, num_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70abce887ca1ebc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*采样 $n$ 条轨迹：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99c76afdbd90093c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:01:00.460943800Z",
     "start_time": "2025-08-18T14:01:00.445658800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_expert_data(n_episode):\n",
    "    states = []\n",
    "    actions = []\n",
    "    for episode in range(n_episode):\n",
    "        episode_return = 0\n",
    "        state, info = env.reset()  # 初始环境状态可不固定，所经历的状态动作对仍具有指导意义\n",
    "        done = False\n",
    "        truncated = False\n",
    "        while not (done or truncated):  # 任务失败或达到最大步数\n",
    "            action = agent.take_action(state)\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            next_state, reward, done, truncated, _ = env.step(action)  # Gymnasium返回值不一样\n",
    "            state = next_state\n",
    "            episode_return += reward\n",
    "        print(episode_return)\n",
    "    return np.array(states), np.array(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b304fe6e36b4678",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*只生成一条轨迹：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b921a0bac3c2b54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:01:03.906292700Z",
     "start_time": "2025-08-18T14:01:02.586455Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n"
     ]
    }
   ],
   "source": [
    "n_episode = 1\n",
    "expert_s, expert_a = sample_expert_data(n_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c10e30991bd06",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*再从中采样 $n$ 个数据对：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b57bc35bd990f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:01:13.987642700Z",
     "start_time": "2025-08-18T14:01:13.971210300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.72294104e-01 -1.43354103e-01  1.28104910e-02  8.42272341e-02]\n",
      " [ 1.48016974e-01 -3.35696250e-01 -1.32817896e-02  3.15589637e-01]\n",
      " [ 3.12507570e-01  2.30062470e-01 -5.39715728e-03 -1.29989833e-01]\n",
      " [ 2.22945094e-01  2.30974346e-01 -1.72858331e-02 -1.50121838e-01]\n",
      " [ 2.64835984e-01  2.32678816e-01  1.98677983e-02 -1.87747002e-01]\n",
      " [ 1.27989084e-01 -1.57186851e-01  6.43744017e-04  3.89326453e-01]\n",
      " [ 2.11684808e-01 -1.49385318e-01  9.21558887e-02  2.18304589e-01]\n",
      " [ 1.75344989e-01 -1.43024594e-01 -1.91703420e-02  7.69324079e-02]\n",
      " [ 1.44222930e-01  2.32494533e-01 -4.75422805e-03 -1.83631346e-01]\n",
      " [ 2.28015080e-01  3.09144799e-02  9.77818370e-02  2.52831399e-01]\n",
      " [ 3.30983400e-01 -1.41496301e-01 -7.71247549e-03  4.32408191e-02]\n",
      " [ 3.72572511e-01 -3.39166164e-01 -5.57604879e-02  3.92826676e-01]\n",
      " [ 4.18744504e-01 -7.07926929e-01  1.12969112e-02  5.03783166e-01]\n",
      " [ 1.95612431e-01 -1.53549373e-01 -3.73520106e-02  3.09340477e-01]\n",
      " [ 1.83799192e-01  3.92020196e-02 -3.05673983e-02  6.87291548e-02]\n",
      " [ 2.40872949e-01 -1.43440351e-01  5.82501665e-02  8.64206403e-02]\n",
      " [ 1.95233330e-01  2.30854377e-01 -5.59087507e-02 -1.47706732e-01]\n",
      " [ 1.79120421e-01  2.33938962e-01 -2.62562558e-02 -2.15557128e-01]\n",
      " [ 9.85555723e-02  8.10458362e-01  2.60867700e-02 -8.98999393e-01]\n",
      " [ 4.93508220e-01 -9.04616773e-01 -4.64835241e-02  8.32308233e-01]\n",
      " [ 6.07369319e-02  2.38230333e-01  2.42919102e-02 -3.10275555e-01]\n",
      " [ 2.09810123e-01  2.30773941e-01 -5.56979096e-03 -1.45683631e-01]\n",
      " [ 1.61088184e-01  5.30942939e-02 -1.24837197e-02 -2.37768769e-01]\n",
      " [ 7.95701444e-02  5.22263832e-02  3.02265882e-02 -2.18728453e-01]\n",
      " [ 2.69937187e-01  6.10754788e-01  6.32477403e-02 -5.05852818e-01]\n",
      " [ 2.38004148e-01 -3.39346796e-01  5.99785782e-02  3.96897763e-01]\n",
      " [ 7.43978024e-02 -1.51252031e-01  1.82487741e-02  2.58439094e-01]\n",
      " [ 5.72589576e-01 -7.15712607e-01 -1.19610928e-01  6.80961311e-01]\n",
      " [ 1.05437927e-01 -3.46586078e-01 -3.21963802e-02  5.56168854e-01]\n",
      " [ 3.07287782e-01 -3.36675853e-01  3.83501244e-03  3.37192029e-01]\n",
      " [ 2.33428553e-01  3.67307812e-02 -2.86691822e-04  1.23202518e-01]\n",
      " [ 3.91430587e-01  9.90091503e-01  1.94043927e-02 -8.49643230e-01]\n",
      " [ 3.20818782e-01 -3.23009193e-01  7.44253993e-02  3.59857604e-02]\n",
      " [ 2.28712067e-01 -3.42964381e-01  5.63498028e-02  4.76555854e-01]\n",
      " [ 1.76299363e-01  4.21819150e-01 -5.25069796e-02 -3.48889470e-01]\n",
      " [ 1.17763072e-01 -3.35495323e-01  1.13942474e-03  3.11114997e-01]\n",
      " [ 2.07558095e-01  2.33858421e-01  9.21253264e-02 -2.14681238e-01]\n",
      " [ 1.98444784e-01 -3.45836401e-01 -3.89081687e-02  5.39760768e-01]\n",
      " [ 2.67838240e-01 -1.41272157e-01  3.05554848e-02  3.84712592e-02]\n",
      " [ 5.30795157e-02 -1.53339490e-01  8.65978841e-03  3.04454207e-01]\n",
      " [ 5.50869443e-02  2.39026740e-01  3.13608199e-02 -3.27925473e-01]\n",
      " [ 3.55380654e-01  4.06251252e-01  3.65552679e-02 -4.90689464e-03]\n",
      " [ 3.37719828e-01 -3.36821824e-01 -1.45218251e-02  3.40467483e-01]\n",
      " [ 4.81240243e-01  6.07073784e-01 -5.26158772e-02 -4.23963189e-01]\n",
      " [ 3.82951617e-01  4.10351790e-02 -7.02975243e-02  2.83481050e-02]\n",
      " [ 5.88402450e-02  4.30369556e-01  1.22647537e-02 -5.37133932e-01]\n",
      " [ 3.48366112e-01 -5.32314181e-01 -2.73545776e-02  6.41637564e-01]\n",
      " [ 3.23496163e-01  2.16587245e-01  3.67499404e-02  1.67364061e-01]\n",
      " [ 1.14764743e-01  1.00521719e+00  8.10678117e-03 -1.18336964e+00]\n",
      " [ 1.96673125e-01  2.30908528e-01  6.19090768e-03 -1.48655757e-01]\n",
      " [ 2.61603892e-01  4.16666210e-01  6.79548457e-02 -2.35355243e-01]\n",
      " [ 3.86053503e-01 -1.55095071e-01 -7.71842748e-02  3.44337255e-01]\n",
      " [ 4.84880134e-02  4.55244370e-02  4.06974889e-02 -7.08331540e-02]\n",
      " [ 3.10897678e-01  2.17673346e-01  3.66324149e-02  1.43390477e-01]\n",
      " [ 2.61122137e-01 -1.56959236e-01 -4.66849748e-03  3.84310931e-01]\n",
      " [ 2.30605841e-01  3.33361253e-02  8.34688023e-02  1.98924765e-01]\n",
      " [ 2.77902246e-01 -3.33656549e-01  3.61173227e-02  2.70900369e-01]\n",
      " [ 7.48231336e-02  4.24732976e-02  2.19800901e-02 -3.46710952e-03]\n",
      " [ 6.53447062e-02 -1.53541669e-01 -1.56553239e-02  3.08963329e-01]\n",
      " [ 7.58953989e-02  5.07006571e-02  2.55001243e-02 -1.85024738e-01]\n",
      " [ 2.71229088e-01 -1.39068097e-01  4.15353328e-02 -1.01757487e-02]\n",
      " [ 2.99399257e-01  2.30188474e-01  5.73108671e-03 -1.32771417e-01]\n",
      " [ 5.80704749e-01  4.23641115e-01 -1.16007358e-01 -3.91096234e-01]\n",
      " [ 3.84282559e-01  4.72162738e-02 -6.78591430e-02 -1.08317606e-01]\n",
      " [ 5.99205673e-01  4.30535674e-01 -1.28604561e-01 -5.44872463e-01]\n",
      " [ 1.99850410e-01  4.26730543e-01 -5.88628873e-02 -4.57490474e-01]\n",
      " [ 3.04003000e-01  4.25227851e-01  3.07565834e-03 -4.23640788e-01]\n",
      " [ 3.65789205e-01 -5.33454299e-01 -4.79039550e-02  6.67420864e-01]\n",
      " [ 2.38486528e-01 -3.41597050e-01  4.40749563e-02  4.46106344e-01]\n",
      " [ 3.86356056e-01  4.51833084e-02 -7.07149580e-02 -6.33848533e-02]\n",
      " [ 1.71779454e-01  2.25995421e-01 -5.16999103e-02 -4.03533392e-02]\n",
      " [ 6.00788713e-01  5.26012033e-02 -1.31726176e-01 -2.28738099e-01]\n",
      " [ 3.46118659e-02  4.07898314e-02  1.28785083e-02  3.36659327e-02]\n",
      " [ 2.98284829e-01  5.88156953e-02  3.60789709e-02 -3.64062279e-01]\n",
      " [ 2.12235272e-01  3.75484154e-02  8.78316984e-02  1.05581611e-01]\n",
      " [ 1.74569294e-01 -3.42560947e-01 -4.70522232e-03  4.66995656e-01]\n",
      " [ 1.63932607e-01 -1.42220929e-01 -1.36676170e-02  5.91948628e-02]\n",
      " [ 1.94792256e-01  4.10086997e-02 -3.79292443e-02  2.88617797e-02]\n",
      " [ 2.57357329e-01  3.72326933e-02 -1.49668474e-02  1.12145104e-01]\n",
      " [ 5.99032402e-01 -3.33347172e-01 -1.35907650e-01  2.66428053e-01]\n",
      " [ 3.47886443e-01 -5.15228093e-01  6.31394237e-02  2.65023112e-01]\n",
      " [ 1.18769862e-01  3.79014574e-02 -6.90332148e-03  9.73872021e-02]\n",
      " [ 2.72439808e-01  4.26214516e-01  2.57092491e-02 -4.45599318e-01]\n",
      " [ 5.07715225e-01 -7.10349500e-01 -5.76501451e-02  5.58331072e-01]\n",
      " [ 1.34869084e-01  8.09991062e-01 -1.55606121e-02 -8.88156652e-01]\n",
      " [ 3.15251142e-01  4.12252039e-01  3.95002253e-02 -1.37514234e-01]\n",
      " [ 8.13571662e-02  5.31177409e-02  3.37014906e-02 -2.38432556e-01]\n",
      " [ 2.13034779e-01  3.84017825e-02 -7.16912374e-02  8.65489244e-02]\n",
      " [ 2.85587251e-01  2.46986732e-01  8.71049520e-03 -5.03329337e-01]\n",
      " [ 2.06542090e-01  4.15793061e-02  1.01194344e-01  1.65121146e-02]\n",
      " [ 2.03359663e-01 -3.40968013e-01 -4.57797609e-02  4.32388574e-01]\n",
      " [ 2.60360777e-01  3.80683355e-02 -6.54248334e-03  9.36992988e-02]\n",
      " [ 1.21809952e-01  3.79642360e-02  7.11871951e-04  9.59993675e-02]\n",
      " [ 1.19473331e-01  5.48490770e-02  6.30522566e-03 -2.76477486e-01]\n",
      " [ 2.19300672e-01 -1.53560475e-01 -7.36783817e-02  3.10229659e-01]\n",
      " [ 4.93985042e-02  2.40040004e-01  3.92808244e-02 -3.50403160e-01]\n",
      " [ 2.66751379e-01  5.43427914e-02  3.58615555e-02 -2.65303552e-01]\n",
      " [ 1.92193598e-01 -3.43262017e-01 -2.96779983e-02  4.82727677e-01]\n",
      " [ 6.03530891e-02 -3.42773408e-01  2.52056215e-02  4.71766233e-01]\n",
      " [ 5.25843382e-01 -9.06408072e-01 -7.51232430e-02  8.73654962e-01]] [0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0\n",
      " 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "random_index = random.sample(range(expert_s.shape[0]), n_samples)\n",
    "expert_s = expert_s[random_index]\n",
    "expert_a = expert_a[random_index]\n",
    "print(expert_s,expert_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506ea5b031e9190",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 行为克隆的代码实践:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800487c8a23c5fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*行为克隆算法：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c8af3bab91ef4c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:01:19.419183Z",
     "start_time": "2025-08-18T14:01:19.405857600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BehaviorClone:\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, lr):\n",
    "        self.policy = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)\n",
    "\n",
    "    def learn(self, states, actions):\n",
    "        states = torch.tensor(states, dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(actions).view(-1, 1).to(device)\n",
    "        log_probs = torch.log(self.policy(states).gather(1, actions))  # 提取当前策略网络对应动作的概率\n",
    "        bc_loss = torch.mean(-log_probs)  # 最大似然估计，最大化对应动作概率\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        bc_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor(np.array([state]), dtype=torch.float).to(device)\n",
    "        probs = self.policy(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb5e053d48a26e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*一次克隆后，测试策略网络效果：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "694127df6c51db7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:01:39.600740700Z",
     "start_time": "2025-08-18T14:01:39.588907800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_agent(agent, env, n_episode):\n",
    "    return_list = []\n",
    "    for episode in range(n_episode):\n",
    "        episode_return = 0\n",
    "        state, info = env.reset()  # 初始环境状态可不固定\n",
    "        done = False\n",
    "        truncated = False\n",
    "        while not (done or truncated):  # 任务失败或达到最大步数\n",
    "            action = agent.take_action(state)\n",
    "            next_state, reward, done, truncated, _ = env.step(action)  # Gymnasium返回值不一样\n",
    "            state = next_state\n",
    "            episode_return += reward\n",
    "        return_list.append(episode_return)\n",
    "    return np.mean(return_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588fcd71ea0d9e48",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*参数设置：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97623c3b0db0b927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:01:41.108166100Z",
     "start_time": "2025-08-18T14:01:41.087284300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "bc_agent = BehaviorClone(state_dim, hidden_dim, action_dim, lr)\n",
    "n_iterations = 1000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a719a5f525f2546",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*训练：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fc613b32c9f7931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:40:26.368524500Z",
     "start_time": "2025-08-18T14:01:42.865613300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条: 100%|██████████| 1000/1000 [38:43<00:00,  2.32s/it, return=303.140]\n"
     ]
    }
   ],
   "source": [
    "test_returns = []\n",
    "with tqdm(total=n_iterations, desc=\"进度条\") as pbar:\n",
    "    for i in range(n_iterations):\n",
    "        sample_indices = np.random.randint(low=0,\n",
    "                                           high=expert_s.shape[0],\n",
    "                                           size=batch_size)  # randint 是有放回采样\n",
    "        bc_agent.learn(expert_s[sample_indices], expert_a[sample_indices])\n",
    "        current_return = test_agent(bc_agent, env, 5)\n",
    "        test_returns.append(current_return)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            pbar.set_postfix({'return': '%.3f' % np.mean(test_returns[-10:])})\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f92daabb84c00",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*实际上，在**初始环境固定**的情况下，**BC** 更加难以学习到 **最优策略**，因为依旧**不完全**的信息数据，会导致学习容易发生**过拟合***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51670302e5b222b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 生成式对抗模仿学习的代码实践:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365eee44671add5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*判别器模型：*\n",
    "> 两层的全连接网络\n",
    "> 模型输入为一个状态动作对，输出一个概率标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa65e57a3e09fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:16:58.457780200Z",
     "start_time": "2025-08-18T15:16:58.438700800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim + action_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        cat = torch.cat([x, a], dim=1)\n",
    "        x = F.relu(self.fc1(cat))\n",
    "        return torch.sigmoid(self.fc2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444f00dfdca9088",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***生成式对抗模仿学习：***\n",
    "> 每一轮迭代中：\n",
    "> 1. **GAIL** 中的策略和环境交互，采样**新的状态动作对**\n",
    "> 2. 基于已有 **专家数据** 和 **策略新采样的数据** ，首先训练 **判别器**\n",
    "> 3. 然后将 **判别器** 的输出转换为 **策略的奖励信号**，指导策略用 **PPO** 算法做训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b579e8de2b704e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:17:00.816334100Z",
     "start_time": "2025-08-18T15:17:00.802823200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GAIL:\n",
    "    def __init__(self, agent, state_dim, action_dim, hidden_dim, lr_d):\n",
    "        self.discriminator = Discriminator(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.discriminator_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=lr_d)\n",
    "        self.agent = agent\n",
    "\n",
    "    def learn(self, expert_s, expert_a, agent_s, agent_a, next_s, dones):\n",
    "        expert_states = torch.tensor(expert_s, dtype=torch.float).to(device)\n",
    "        expert_actions = torch.tensor(expert_a).to(device)\n",
    "        agent_states = torch.tensor(np.array(agent_s), dtype=torch.float).to(device)\n",
    "        agent_actions = torch.tensor(agent_a).to(device)\n",
    "        # 独热编码\n",
    "        expert_actions = F.one_hot(expert_actions, num_classes=2).float()\n",
    "        agent_actions = F.one_hot(agent_actions, num_classes=2).float()\n",
    "        # 判断器更新\n",
    "        expert_prob = self.discriminator(expert_states, expert_actions)\n",
    "        agent_prob = self.discriminator(agent_states, agent_actions)\n",
    "        discriminator_loss = nn.BCELoss()(\n",
    "            agent_prob, torch.ones_like(agent_prob)) + nn.BCELoss()(\n",
    "                expert_prob, torch.zeros_like(expert_prob))  # 判别器的二分类交叉熵损失\n",
    "        self.discriminator_optimizer.zero_grad()\n",
    "        discriminator_loss.backward()\n",
    "        self.discriminator_optimizer.step()\n",
    "        # 策略更新\n",
    "        rewards = -torch.log(agent_prob).detach().cpu().numpy()  # 不使用环境反馈的奖励\n",
    "        transition_dict = {\n",
    "            'states': agent_s,\n",
    "            'actions': agent_a,\n",
    "            'rewards': rewards,\n",
    "            'next_states': next_s,\n",
    "            'dones': dones\n",
    "        }\n",
    "        self.agent.update(transition_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a87971fcc94414",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*参数设置：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6292b27e2a90d0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:17:04.095252300Z",
     "start_time": "2025-08-18T15:17:04.077726600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_gail = PPO(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda,\n",
    "            epochs, eps, gamma, device)\n",
    "lr_d = 1e-3\n",
    "gail = GAIL(agent_gail, state_dim, action_dim, hidden_dim, lr_d)\n",
    "n_episode = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf1a8862d5b502",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*训练：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e753e5c7a577b4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:23:28.488547Z",
     "start_time": "2025-08-18T15:17:06.319904Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条: 100%|██████████| 500/500 [06:22<00:00,  1.31it/s, return=500.000]\n"
     ]
    }
   ],
   "source": [
    "return_list = []\n",
    "with tqdm(total=n_episode, desc=\"进度条\") as pbar:\n",
    "    for i in range(n_episode):\n",
    "        episode_return = 0\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        truncated = False\n",
    "        state_list = []\n",
    "        action_list = []\n",
    "        next_state_list = []\n",
    "        done_list = []\n",
    "        while not (done or truncated):  # 任务失败或达到最大步数\n",
    "            action = agent_gail.take_action(state)\n",
    "            next_state, reward, done, truncated, _ = env.step(action)  # Gymnasium返回值不一样\n",
    "            state_list.append(state)\n",
    "            action_list.append(action)\n",
    "            next_state_list.append(next_state)\n",
    "            done_list.append(done)\n",
    "            state = next_state\n",
    "            episode_return += reward\n",
    "        return_list.append(episode_return)\n",
    "        gail.learn(expert_s, expert_a, state_list, action_list, next_state_list, done_list)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            pbar.set_postfix({'return': '%.3f' % np.mean(return_list[-10:])})\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 绘图对比："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "592b09934dac92c9"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a91d303fd9caa44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T16:23:42.160392Z",
     "start_time": "2025-08-18T16:23:41.479578800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "episodes_list_bc = list(range(len(test_returns)))\n",
    "mv1_return = moving_average(test_returns, 9)\n",
    "episodes_list_gail = list(range(len(return_list)))\n",
    "mv2_return = moving_average(return_list, 9)\n",
    "# 创建 DataFrame\n",
    "df1 = pd.DataFrame({'Episodes': episodes_list_bc, 'Returns': mv1_return})\n",
    "df2 = pd.DataFrame({'Episodes': episodes_list_gail, 'Returns': mv2_return})\n",
    "# 保存为 CSV 文件\n",
    "df1.to_csv('PPO_bc_CartPole-v1_mv_returns_data.csv', index=False)\n",
    "df2.to_csv('PPO_gail_CartPole-v1_mv_returns_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "id": "39e76be73e145e62",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T10:27:46.474884Z",
     "start_time": "2025-09-25T10:27:45.943481Z"
    }
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/PPO_bc_CartPole-v1_mv_returns_data.csv')  # 从 CSV 文件中读取数据\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['Episodes'], y=df['Returns'], mode='lines', name='Returns'))\n",
    "fig.update_layout(\n",
    "    title='BC on CartPole-v1',\n",
    "    xaxis_title='Episodes',\n",
    "    yaxis_title='Returns',\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Returns",
         "x": {
          "dtype": "i2",
          "bdata": "AAABAAIAAwAEAAUABgAHAAgACQAKAAsADAANAA4ADwAQABEAEgATABQAFQAWABcAGAAZABoAGwAcAB0AHgAfACAAIQAiACMAJAAlACYAJwAoACkAKgArACwALQAuAC8AMAAxADIAMwA0ADUANgA3ADgAOQA6ADsAPAA9AD4APwBAAEEAQgBDAEQARQBGAEcASABJAEoASwBMAE0ATgBPAFAAUQBSAFMAVABVAFYAVwBYAFkAWgBbAFwAXQBeAF8AYABhAGIAYwBkAGUAZgBnAGgAaQBqAGsAbABtAG4AbwBwAHEAcgBzAHQAdQB2AHcAeAB5AHoAewB8AH0AfgB/AIAAgQCCAIMAhACFAIYAhwCIAIkAigCLAIwAjQCOAI8AkACRAJIAkwCUAJUAlgCXAJgAmQCaAJsAnACdAJ4AnwCgAKEAogCjAKQApQCmAKcAqACpAKoAqwCsAK0ArgCvALAAsQCyALMAtAC1ALYAtwC4ALkAugC7ALwAvQC+AL8AwADBAMIAwwDEAMUAxgDHAMgAyQDKAMsAzADNAM4AzwDQANEA0gDTANQA1QDWANcA2ADZANoA2wDcAN0A3gDfAOAA4QDiAOMA5ADlAOYA5wDoAOkA6gDrAOwA7QDuAO8A8ADxAPIA8wD0APUA9gD3APgA+QD6APsA/AD9AP4A/wAAAQEBAgEDAQQBBQEGAQcBCAEJAQoBCwEMAQ0BDgEPARABEQESARMBFAEVARYBFwEYARkBGgEbARwBHQEeAR8BIAEhASIBIwEkASUBJgEnASgBKQEqASsBLAEtAS4BLwEwATEBMgEzATQBNQE2ATcBOAE5AToBOwE8AT0BPgE/AUABQQFCAUMBRAFFAUYBRwFIAUkBSgFLAUwBTQFOAU8BUAFRAVIBUwFUAVUBVgFXAVgBWQFaAVsBXAFdAV4BXwFgAWEBYgFjAWQBZQFmAWcBaAFpAWoBawFsAW0BbgFvAXABcQFyAXMBdAF1AXYBdwF4AXkBegF7AXwBfQF+AX8BgAGBAYIBgwGEAYUBhgGHAYgBiQGKAYsBjAGNAY4BjwGQAZEBkgGTAZQBlQGWAZcBmAGZAZoBmwGcAZ0BngGfAaABoQGiAaMBpAGlAaYBpwGoAakBqgGrAawBrQGuAa8BsAGxAbIBswG0AbUBtgG3AbgBuQG6AbsBvAG9Ab4BvwHAAcEBwgHDAcQBxQHGAccByAHJAcoBywHMAc0BzgHPAdAB0QHSAdMB1AHVAdYB1wHYAdkB2gHbAdwB3QHeAd8B4AHhAeIB4wHkAeUB5gHnAegB6QHqAesB7AHtAe4B7wHwAfEB8gHzAfQB9QH2AfcB+AH5AfoB+wH8Af0B/gH/AQACAQICAgMCBAIFAgYCBwIIAgkCCgILAgwCDQIOAg8CEAIRAhICEwIUAhUCFgIXAhgCGQIaAhsCHAIdAh4CHwIgAiECIgIjAiQCJQImAicCKAIpAioCKwIsAi0CLgIvAjACMQIyAjMCNAI1AjYCNwI4AjkCOgI7AjwCPQI+Aj8CQAJBAkICQwJEAkUCRgJHAkgCSQJKAksCTAJNAk4CTwJQAlECUgJTAlQCVQJWAlcCWAJZAloCWwJcAl0CXgJfAmACYQJiAmMCZAJlAmYCZwJoAmkCagJrAmwCbQJuAm8CcAJxAnICcwJ0AnUCdgJ3AngCeQJ6AnsCfAJ9An4CfwKAAoECggKDAoQChQKGAocCiAKJAooCiwKMAo0CjgKPApACkQKSApMClAKVApYClwKYApkCmgKbApwCnQKeAp8CoAKhAqICowKkAqUCpgKnAqgCqQKqAqsCrAKtAq4CrwKwArECsgKzArQCtQK2ArcCuAK5AroCuwK8Ar0CvgK/AsACwQLCAsMCxALFAsYCxwLIAskCygLLAswCzQLOAs8C0ALRAtIC0wLUAtUC1gLXAtgC2QLaAtsC3ALdAt4C3wLgAuEC4gLjAuQC5QLmAucC6ALpAuoC6wLsAu0C7gLvAvAC8QLyAvMC9AL1AvYC9wL4AvkC+gL7AvwC/QL+Av8CAAMBAwIDAwMEAwUDBgMHAwgDCQMKAwsDDAMNAw4DDwMQAxEDEgMTAxQDFQMWAxcDGAMZAxoDGwMcAx0DHgMfAyADIQMiAyMDJAMlAyYDJwMoAykDKgMrAywDLQMuAy8DMAMxAzIDMwM0AzUDNgM3AzgDOQM6AzsDPAM9Az4DPwNAA0EDQgNDA0QDRQNGA0cDSANJA0oDSwNMA00DTgNPA1ADUQNSA1MDVANVA1YDVwNYA1kDWgNbA1wDXQNeA18DYANhA2IDYwNkA2UDZgNnA2gDaQNqA2sDbANtA24DbwNwA3EDcgNzA3QDdQN2A3cDeAN5A3oDewN8A30DfgN/A4ADgQOCA4MDhAOFA4YDhwOIA4kDigOLA4wDjQOOA48DkAORA5IDkwOUA5UDlgOXA5gDmQOaA5sDnAOdA54DnwOgA6EDogOjA6QDpQOmA6cDqAOpA6oDqwOsA60DrgOvA7ADsQOyA7MDtAO1A7YDtwO4A7kDugO7A7wDvQO+A78DwAPBA8IDwwPEA8UDxgPHA8gDyQPKA8sDzAPNA84DzwPQA9ED0gPTA9QD1QPWA9cD2APZA9oD2wPcA90D3gPfA+AD4QPiA+MD5APlA+YD5wM="
         },
         "y": {
          "dtype": "f8",
          "bdata": "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"
         },
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "BC on CartPole-v1"
        },
        "xaxis": {
         "title": {
          "text": "Episodes"
         }
        },
        "yaxis": {
         "title": {
          "text": "Returns"
         }
        },
        "showlegend": true
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "35b3a628d91be03e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T10:27:53.109843Z",
     "start_time": "2025-09-25T10:27:53.084904Z"
    }
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/PPO_gail_CartPole-v1_mv_returns_data.csv')  # 从 CSV 文件中读取数据\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['Episodes'], y=df['Returns'], mode='lines', name='Returns'))\n",
    "fig.update_layout(\n",
    "    title='GAIL on CartPole-v1',\n",
    "    xaxis_title='Episodes',\n",
    "    yaxis_title='Returns',\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Returns",
         "x": {
          "dtype": "i2",
          "bdata": "AAABAAIAAwAEAAUABgAHAAgACQAKAAsADAANAA4ADwAQABEAEgATABQAFQAWABcAGAAZABoAGwAcAB0AHgAfACAAIQAiACMAJAAlACYAJwAoACkAKgArACwALQAuAC8AMAAxADIAMwA0ADUANgA3ADgAOQA6ADsAPAA9AD4APwBAAEEAQgBDAEQARQBGAEcASABJAEoASwBMAE0ATgBPAFAAUQBSAFMAVABVAFYAVwBYAFkAWgBbAFwAXQBeAF8AYABhAGIAYwBkAGUAZgBnAGgAaQBqAGsAbABtAG4AbwBwAHEAcgBzAHQAdQB2AHcAeAB5AHoAewB8AH0AfgB/AIAAgQCCAIMAhACFAIYAhwCIAIkAigCLAIwAjQCOAI8AkACRAJIAkwCUAJUAlgCXAJgAmQCaAJsAnACdAJ4AnwCgAKEAogCjAKQApQCmAKcAqACpAKoAqwCsAK0ArgCvALAAsQCyALMAtAC1ALYAtwC4ALkAugC7ALwAvQC+AL8AwADBAMIAwwDEAMUAxgDHAMgAyQDKAMsAzADNAM4AzwDQANEA0gDTANQA1QDWANcA2ADZANoA2wDcAN0A3gDfAOAA4QDiAOMA5ADlAOYA5wDoAOkA6gDrAOwA7QDuAO8A8ADxAPIA8wD0APUA9gD3APgA+QD6APsA/AD9AP4A/wAAAQEBAgEDAQQBBQEGAQcBCAEJAQoBCwEMAQ0BDgEPARABEQESARMBFAEVARYBFwEYARkBGgEbARwBHQEeAR8BIAEhASIBIwEkASUBJgEnASgBKQEqASsBLAEtAS4BLwEwATEBMgEzATQBNQE2ATcBOAE5AToBOwE8AT0BPgE/AUABQQFCAUMBRAFFAUYBRwFIAUkBSgFLAUwBTQFOAU8BUAFRAVIBUwFUAVUBVgFXAVgBWQFaAVsBXAFdAV4BXwFgAWEBYgFjAWQBZQFmAWcBaAFpAWoBawFsAW0BbgFvAXABcQFyAXMBdAF1AXYBdwF4AXkBegF7AXwBfQF+AX8BgAGBAYIBgwGEAYUBhgGHAYgBiQGKAYsBjAGNAY4BjwGQAZEBkgGTAZQBlQGWAZcBmAGZAZoBmwGcAZ0BngGfAaABoQGiAaMBpAGlAaYBpwGoAakBqgGrAawBrQGuAa8BsAGxAbIBswG0AbUBtgG3AbgBuQG6AbsBvAG9Ab4BvwHAAcEBwgHDAcQBxQHGAccByAHJAcoBywHMAc0BzgHPAdAB0QHSAdMB1AHVAdYB1wHYAdkB2gHbAdwB3QHeAd8B4AHhAeIB4wHkAeUB5gHnAegB6QHqAesB7AHtAe4B7wHwAfEB8gHzAQ=="
         },
         "y": {
          "dtype": "f8",
          "bdata": "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"
         },
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "GAIL on CartPole-v1"
        },
        "xaxis": {
         "title": {
          "text": "Episodes"
         }
        },
        "yaxis": {
         "title": {
          "text": "Returns"
         }
        },
        "showlegend": true
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "45bdceb09037ca30",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*通过对比，可以感受到，在 **数据样本有限** 的情况下，**BC** 难以学习到 **最优策略**，而 **GAIL** 在 **相同的专家数据** 下则可以取得非常好的效果*\n",
    "- 一方面归因于 **GAIL** 的训练目标是拉近策略和专家的**占用度量**，而非简单复制十分贴合模仿学习任务的目标，避免了 BC 中的 **复合误差问题**；\n",
    "- 另一方面是在 **GAIL** 训练中，策略可以和环境交互出 **更多的数据**，并通过判别器，转化为了专门的 **策略更新指导奖励信号**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1cc474b0cbae8",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
