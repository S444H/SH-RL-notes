{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f852de82a459f6dc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 20.基于模型的策略优化 (model-based policy optimization，MBPO）\n",
    "- **Dyna-Q** 算法中的模型只存储之前遇到的数据，只适用于 **表格型环境**；\n",
    "- 在 **连续型** 状态和动作的环境中，若继续利用 **Dyna** 的思想，可以像 **PETS** 算法一样学习一个用 **神经网络环境模型**，然后在任意状态和动作下用 **环境模型** 来生成一些虚拟数据来帮助进行策略的学习；\n",
    "- 如此，对 **真实环境** 中样本的需求量会减少，通常会比 **无模型** 的强化学习方法具有更高的采样效率 —— **MBPO** 算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610f6845d373ac8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 20.1 MBPO 原理\n",
    "> **加州大学伯克利分校 (UC Berkeley)** 的研究员在 2019 年的 NeurIPS 会议中提出 **MBPO** 算法 [When to Trust Your Model: Model-Based Policy Optimization](https://arxiv.org/abs/1906.08253) \n",
    "\n",
    "> 研究证明，在多个 **MuJoCo** 连续控制任务上，**MBPO** 的性能相比 **基于模型** 的方法更优，甚至在样本效率上超过了一些 **无模型算法**（如 **SAC**）\n",
    "> **MBPO** 被认为是 **基于模型的强化学习领域中的里程碑式算法**，成为深度强化学习中最重要的**基于模型**的强化学习算法之一，不少之后的工作都是在此基础上进行的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f759cf81c5637a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> **MBPO** 算法基于 **两个关键** 的观察：\n",
    "- 随着环境模型的 **推演步数** 变长，模型累积的 **复合误差** 会快速增加，使得环境模型得出的结果变得很 **不可靠**\n",
    "- **推演步数** 必须要 **权衡**  *推演步数长，复合误差大* 的 **负面作用** 与 *推演步数长，训练策略更优* 的 **正面作用**\n",
    "> 在这两个观察的基础之上提出了一种 **分支推演（branched rollout）**  的思想：*只使用环境模型 **从之前访问过的真实状态开始** 进行 **较短步数** 的推演，**而非**从初始状态开始进行**完整的推演**，**避免**长时间依赖预测，**减弱**模型误差累积的影响：*\n",
    "![示意图](Illustrations/分支推演示意图.png)\n",
    "- **分支推演的长度$k$** 是 **平衡** 样本效率和策略性能的 **重要超参数**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07b2407896f1c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### *真实环境下策略性能提升的单调性保障*\n",
    "> 基于模型的方法往往是在 **环境模型** 中提升策略的性能，但这并不能保证在 **真实环境** 中策略性能也有所提升，对此需要保证：\n",
    "\n",
    "$$\\eta[\\pi]\\geq\\hat{\\eta}[\\pi]-\\left[\\frac{2\\gamma r_{\\max}(\\epsilon_m+2\\epsilon_\\pi)}{(1-\\gamma)^2}+\\frac{4r_{\\max}\\epsilon_\\pi}{(1-\\gamma)}\\right]$$\n",
    "$$C=\\left[\\frac{2\\gamma r_{\\max}(\\epsilon_m+2\\epsilon_\\pi)}{(1-\\gamma)^2}+\\frac{4r_{\\max}\\epsilon_\\pi}{(1-\\gamma)}\\right]$$\n",
    "\n",
    "- $\\eta[\\pi]$表示策略在 **真实环境** 中的 **期望回报**\n",
    "- $\\hat{\\eta}[\\pi]$表示策略在 **模型环境** 中的 **期望回报**\n",
    "- $\\epsilon_m$: **模型误差**，指模型在预测环境动态时的误差度量，代表着 **模型预测** 与 **真实环境状态转移**之间的差异（单步误差）\n",
    "- $\\epsilon_\\pi$: **策略误差**，指策略执行时的误差度量，刻画了在 **同一当前策略$\\pi$** 下，**模型预测的状态轨迹** 与 **真实轨迹** 之间的偏移（长期误差）\n",
    "\n",
    "> 误差项的构造：\n",
    "- $\\frac{2\\gamma r_{\\max}(\\epsilon_m + 2\\epsilon_\\pi)}{(1-\\gamma)^2}$ 捕捉 **“模型不准 + 策略偏移”** 引起的长期累积误差\n",
    "- $\\frac{4r_{\\max} \\epsilon_\\pi}{(1-\\gamma)}$ 捕捉 **“即使模型准，但分布不同”** 造成的性能差\n",
    "- 具体的推导过程见原论文附录 **Appendix A**\n",
    "\n",
    "> 这意味着如果 **模型环境** 策略性能的提升可以超过 **performance bound（性能界/性能下界）$C$** ，理论上就可以在 **真实环境** 中取得策略性能的提升"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1cf421154e88d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### *模型推演长度*\n",
    "> **MBPO** 对 **模型误差 $\\epsilon_m$** 进行了优化：使用 **策略相关模型误差$\\epsilon_{m'}$** ，关注 **当前策略$\\pi$** 在 **有限步 rollout（推演片段）** 下可能访问的分布中与真实分布的最大差异，而不是将在 **环境模型** 上训练策略时所触及到的 **所有分布** 都考虑进来。\n",
    "> 此时，两种误差都被局限在 **当前策略的有限步访问分布** 中，将两者结合起来，可更准确地估计策略在模型里的性能差异，从而指导安全的 **rollout步长$H$** 和 **策略优化**：\n",
    "![策略偏移与模型误差](Illustrations/策略偏移与模型误差.png)\n",
    "\n",
    "> 对 $\\epsilon_m'$ 在 $\\epsilon_\\pi=0$ 附近做一阶展开：\n",
    "$$\\epsilon_m^{\\prime}(\\epsilon_\\pi)\\approx\\epsilon_m^{\\prime}|_{\\epsilon_\\pi=0}+\\epsilon_\\pi\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$$\n",
    "- 并不是数学上严格意义的泰勒一阶展开，而是一种 **改进的近似**，只是为了 **捕捉策略偏移对模型误差的增量影响**（直观作用类似一阶展开）\n",
    "- 没有闭式表达式能把 $\\epsilon_m'$ 精确写成 $\\epsilon_\\pi$ 的函数\n",
    "\n",
    "\n",
    "> 当策略偏移为零时，**环境误差** 退化，考虑 **全局的分布**：\n",
    "$$\\epsilon_m^{\\prime}(\\epsilon_\\pi)\\approx\\epsilon_m+\\epsilon_\\pi\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}.$$\n",
    "\n",
    "> 再结合上 $k$ 步 **分支推演**，得到一个 **新的策略期望回报界**：\n",
    "$$\\eta[\\pi]\\geq\\eta^\\mathrm{branch}[\\pi]-2r_\\mathrm{max}\\left[\\frac{\\gamma^{k+1}\\epsilon_\\pi}{(1-\\gamma)^2}+\\frac{\\gamma^k\\epsilon_\\pi}{(1-\\gamma)}+\\frac{k}{1-\\gamma}\\epsilon_{m^{\\prime}}\\right]$$\n",
    "\n",
    "- 具体的推导过程见原论文附录 **Appendix A**\n",
    "\n",
    "> 此时，在策略误差一定时，当推演步数$H$变大，$\\frac{\\gamma^{k+1}\\epsilon_\\pi}{(1-\\gamma)^2}+\\frac{\\gamma^k\\epsilon_\\pi}{(1-\\gamma)}$减小\n",
    "> 虽然$\\frac{k}{1-\\gamma}\\epsilon_{m^{\\prime}}$ 增大，但如果 **策略转移损害对模型准确度的影响$\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$** 足够小（在主流的机器人运动环境 **Mojoco** 的典型场景中，其数量级非常小，大约都在$[10^{-4},10^{-2}]$）\n",
    "> 那么就存在一个 **正推演步长$k$**，使 **策略提升** 有效。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4aaf81ecd0a1d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 需要注意的是，在高随机性的离散状态环境中，往往环境模型的拟合精度较低，以至于$\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$较大，此时使用基于 **分支推演** 的方法 **效果有限**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88804a095089bc8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 20.2 MBPO 代码实践(Pendulum-v1)\n",
    "\n",
    "1. **MBPO** 算法与 **Dyna-Q** 算法十分类似。但 **Dyna-Q** 采用的**无模型强化学习部分**是 **Q-learning**，而 **MBPO** 是基于 **SAC**\n",
    "2. **MBPO** 算法关于 **环境模型的构建** 和 **PETS** 算法中一致，都使用 **模型集成** 的方式\n",
    "3. **MBPO** 算法使用了 **模型生成的数据** 和 **真实环境的数据** 混合训练策略，提升了 **样本效率** 和 **稳定性**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215b9c55a82a9e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "导入相关库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5dd07c4f584c01c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.250270600Z",
     "start_time": "2025-08-25T12:04:47.030841100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 基本库\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "\n",
    "# 神经网络\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "# Gymnasium 是一个用于开发和测试强化学习算法的工具库，为 OpenAI Gym 的更新版本（2021迁移开发）\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "656295b26a8d3a9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.251270100Z",
     "start_time": "2025-08-25T12:04:47.037050900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259bf44a695302f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  SAC 部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ef13e2509f930",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*定义策略网络和价值网络:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1295676e1952fb36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.400200800Z",
     "start_time": "2025-08-25T12:04:47.048371200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PolicyNetContinuous(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, action_bound):\n",
    "        super(PolicyNetContinuous, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc_mu = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.fc_std = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.action_bound = action_bound\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        std = F.softplus(self.fc_std(x))\n",
    "        \n",
    "        dist = Normal(mu, std)  # 构建高斯分布\n",
    "        normal_sample = dist.rsample()  # rsample()是重参数化采样\n",
    "        log_prob = dist.log_prob(normal_sample)\n",
    "        # 动作范围映射\n",
    "        action = torch.tanh(normal_sample)  # a=tanh(z) \n",
    "        action = action * self.action_bound\n",
    "        # 概率密度的变量替换\n",
    "        log_prob = log_prob - torch.log(1 - torch.tanh(action).pow(2) + 1e-7)  # 1-tanh(z)^2是tanh的导数（sech²），加1e-7避免log(0)\n",
    "        return action, log_prob\n",
    "\n",
    "\n",
    "class QValueNetContinuous(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(QValueNetContinuous, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim + action_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_out = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        cat = torch.cat([x, a], dim=1)\n",
    "        x = F.relu(self.fc1(cat))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5de50314106cab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*定义 **SAC** 算法（连续动作）：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "26bbfbe3da8b9762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.419721300Z",
     "start_time": "2025-08-25T12:04:47.054884Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SACContinuous:\n",
    "    \"\"\" 处理连续动作空间 \"\"\"\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, action_bound,\n",
    "                 actor_lr, critic_lr, alpha_lr, target_entropy, tau, gamma,\n",
    "                 device):\n",
    "        self.actor = PolicyNetContinuous(state_dim, hidden_dim, action_dim, action_bound).to(device)  # 策略网络\n",
    "        # 双Q网络\n",
    "        self.critic_1 = QValueNetContinuous(state_dim, hidden_dim, action_dim).to(device)  # 第一个Q网络\n",
    "        self.critic_2 = QValueNetContinuous(state_dim, hidden_dim, action_dim).to(device)  # 第二个Q网络\n",
    "        self.target_critic_1 = QValueNetContinuous(state_dim, hidden_dim, action_dim).to(device)  # 第一个目标Q网络\n",
    "        self.target_critic_2 = QValueNetContinuous(state_dim, hidden_dim, action_dim).to(device)  # 第二个目标Q网络\n",
    "        # 令目标Q网络的初始参数和Q网络一样\n",
    "        self.target_critic_1.load_state_dict(self.critic_1.state_dict())\n",
    "        self.target_critic_2.load_state_dict(self.critic_2.state_dict())\n",
    "        \n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_1_optimizer = torch.optim.Adam(self.critic_1.parameters(), lr=critic_lr)\n",
    "        self.critic_2_optimizer = torch.optim.Adam(self.critic_2.parameters(), lr=critic_lr)\n",
    "        \n",
    "        # 使用温度参数alpha的log值,可以确保 α 永远是正数,使训练结果比较稳定\n",
    "        self.log_alpha = torch.tensor(np.log(0.01), dtype=torch.float)\n",
    "        self.log_alpha.requires_grad = True  # 可以对alpha求梯度\n",
    "        self.log_alpha_optimizer = torch.optim.Adam([self.log_alpha], lr=alpha_lr)\n",
    "        \n",
    "        self.target_entropy = target_entropy  # 目标熵的大小\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau  # 软更新步长\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor(np.array([state]), dtype=torch.float).to(self.device)\n",
    "        action = self.actor(state)[0]\n",
    "        return [action.item()]\n",
    "    \n",
    "    # 计算目标Q值\n",
    "    def calc_target(self, rewards, next_states, dones):  # 计算目标Q值\n",
    "        next_actions, log_prob = self.actor(next_states)\n",
    "        entropy = -log_prob  # 连续动作熵用动作采样的负对数概率近似\n",
    "        q1_value = self.target_critic_1(next_states, next_actions)\n",
    "        q2_value = self.target_critic_2(next_states, next_actions)\n",
    "        next_value = torch.min(q1_value,q2_value) + self.log_alpha.exp() * entropy\n",
    "        td_target = rewards + self.gamma * next_value * (1 - dones)\n",
    "        return td_target\n",
    "    \n",
    "    # DDPG中的软更新\n",
    "    def soft_update(self, net, target_net):\n",
    "        for param_target, param in zip(target_net.parameters(), net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - self.tau) + param.data * self.tau)\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "\n",
    "\n",
    "        # 更新两个Q网络\n",
    "        td_target = self.calc_target(rewards, next_states, dones)\n",
    "        critic_1_loss = torch.mean(F.mse_loss(self.critic_1(states, actions), td_target.detach()))\n",
    "        critic_2_loss = torch.mean(F.mse_loss(self.critic_2(states, actions), td_target.detach()))\n",
    "        self.critic_1_optimizer.zero_grad()\n",
    "        critic_1_loss.backward()\n",
    "        self.critic_1_optimizer.step()\n",
    "        self.critic_2_optimizer.zero_grad()\n",
    "        critic_2_loss.backward()\n",
    "        self.critic_2_optimizer.step()\n",
    "\n",
    "        # 更新策略网络\n",
    "        new_actions, log_prob = self.actor(states)\n",
    "        entropy = -log_prob  # 连续动作熵用动作采样的负对数概率近似\n",
    "        q1_value = self.critic_1(states, new_actions)\n",
    "        q2_value = self.critic_2(states, new_actions)\n",
    "        actor_loss = torch.mean(-self.log_alpha.exp() * entropy - torch.min(q1_value, q2_value))\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # 更新alpha值\n",
    "        alpha_loss = torch.mean((entropy - self.target_entropy).detach() * self.log_alpha.exp())\n",
    "        self.log_alpha_optimizer.zero_grad()\n",
    "        alpha_loss.backward()\n",
    "        self.log_alpha_optimizer.step()\n",
    "\n",
    "        # 软更新目标Q网络\n",
    "        self.soft_update(self.critic_1, self.target_critic_1)\n",
    "        self.soft_update(self.critic_2, self.target_critic_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4662b620f2996e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 集成环境模型构建(沿用 PETS 算法中的)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6d39a36ce69fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***激活函数定义：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a104460429826fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.437716800Z",
     "start_time": "2025-08-25T12:04:47.069243700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \"\"\" Swish激活函数 \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd901bab6d55242",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***初始化网络层参数：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e9e9b605abbce392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.452718800Z",
     "start_time": "2025-08-25T12:04:47.077218500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_weights(m):  # m 为某个网络层\n",
    "    \"\"\" 初始化模型权重 \"\"\"\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        \"\"\" 截断正态分布 \"\"\"\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)  # 用均值为 mean、标准差为 std 的正态分布随机数填充张量t \n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):  # 如果所有值都在范围内 (torch.sum(cond) == 0)，就退出循环\n",
    "                break\n",
    "            t = torch.where(\n",
    "                cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),mean=mean,std=std), \n",
    "                t)  # 如果有越界的值，就重新采样，并用 torch.where 把这些位置替换成新的采样值\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):  # 若 m 是全连接层（nn.Linear）或 自定义层 FCLayer\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))  # 权重 m.weight 用截断正态分布初始化\n",
    "        m.bias.data.fill_(0.0)  # 偏置 m.bias 全部设为 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872cebf30081e58",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***自定义的全连接层：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bb5d0f47a18109e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.457721200Z",
     "start_time": "2025-08-25T12:04:47.084731800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    \"\"\" 自定义的全连接层 (FCLayer)，支持 ensemble（集成） \"\"\"\n",
    "    # ensemble_size: 集成的个数（即同时训练多少组独立的参数）\n",
    "    # activation: 激活函数（如 ReLU、Swish）\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(\n",
    "            torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))  # 矩阵计算\n",
    "            # X:(ensemble_size, batch_size, input_dim)\n",
    "            # W:(ensemble_size, input_dim, output_dim)\n",
    "            # 偏置bias扩展到 (ensemble_size, batch_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8eed1a8d668405",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***集成环境模型定义：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8c28232d7750cc95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.461724200Z",
     "start_time": "2025-08-25T12:04:47.096618900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\" 环境模型集成 \"\"\"\n",
    "    def __init__(self,\n",
    "                 state_dim,\n",
    "                 action_dim,\n",
    "                 ensemble_size=5,  # 模型成员总数为ensemble_size，对应训练ensemble_size组权重\n",
    "                 learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self._output_dim = (state_dim + 1) * 2  # 预测奖励与状态增量 以及 对应方差\n",
    "        # 方差上界和下界\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),\n",
    "                                        requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),\n",
    "                                        requires_grad=False)\n",
    "        # 集成模型中每个成员为5层神经网络\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size, Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size, nn.Identity())  # nn.Identity()，原样返回输入\n",
    "        self.apply(init_weights)  # 对所有 nn.Linear 和 FCLayer 层做权重初始化\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):  # 选择是否返回对数方差\n",
    "        # 前向传播\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        # 输出一分为二\n",
    "        mean   = ret[:, :, :self._output_dim // 2]   # 前一半 -> 均值\n",
    "        raw_lv = ret[:, :, self._output_dim // 2:]   # 后一半 -> 原始对数方差 logvar（未约束）\n",
    "        # 使用softplus函数,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(self._max_logvar - raw_lv)\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):  # 是否选择带方差的 loss\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            # 对应简化损失函数\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) * inverse_var,\n",
    "                                             dim=-1),dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            # 退化为普通的 MSE\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train_my(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        # 惩罚 _max_logvar 太大；惩罚 _min_logvar 太小\n",
    "        loss += 0.01 * torch.sum(self._max_logvar) - 0.01 * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796e740c2842129",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***模型的训练：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "921f38c740dc8e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.475719500Z",
     "start_time": "2025-08-25T12:04:47.102967800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnsembleDynamicsModel:\n",
    "    def __init__(self, state_dim, action_dim, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim,\n",
    "                                   action_dim,\n",
    "                                   ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0  # 在 5 次没有获得表现提升时就结束训练\n",
    "        # 记录每个网络的最佳 epoch 和对应验证集损失，用于早停和选择最优模型\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "    # 模型成员并行训练\n",
    "    def train(self,\n",
    "              inputs,\n",
    "              labels,\n",
    "              batch_size=64,\n",
    "              holdout_ratio=0.1,\n",
    "              max_iter=20):\n",
    "        # 设置训练集与验证集，holdout_ratio 默认为 0.1，即 10% 数据用于验证\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        \n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]  # 训练集：90%\n",
    "        holdout_inputs, holdout_labels = inputs[:num_holdout], labels[:num_holdout]  # 验证集：10%\n",
    "        # 复制验证集数据，使每个网络都能独立计算损失\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat([self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat([self._num_network, 1, 1])\n",
    "\n",
    "        # itertools.count() 会无限产生整数：0,1,2,… ；实际训练结束条件在循环内部通过 _save_best 和 epoch > max_iter 来控制\n",
    "        for epoch in itertools.count():  # itertools.count() 会无限产生整数：0,1,2,…\n",
    "            # 为每个模型成员生成独立的训练顺序（认知不确定性）\n",
    "            train_index = np.vstack([\n",
    "                np.random.permutation(train_inputs.shape[0])\n",
    "                for _ in range(self._num_network)\n",
    "            ])\n",
    "            # Mini-batch 训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):  # 按 batch_size 分块，逐个 batch 进行训练\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos +batch_size]\n",
    "                train_input = torch.from_numpy(train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(train_labels[batch_index]).float().to(device)\n",
    "\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train_my(loss)\n",
    "                \n",
    "            # 用验证集评估 Mini-batch训练后 模型的性能\n",
    "            with torch.no_grad():  # 在其作用域内禁止梯度计算\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean,\n",
    "                                                    logvar,\n",
    "                                                    holdout_labels,\n",
    "                                                    use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()  # GPU 张量不能直接用于大多数 Python 操作\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False  # 标记本轮是否有网络取得了显著改进\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):\n",
    "        inputs = np.tile(inputs, (self._num_network, 1, 1))\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float).to(device)\n",
    "        mean, var = self.model(inputs, return_log_var=False)\n",
    "        return mean.detach().cpu().numpy(), var.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc37fddf5adc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 修改部分:\n",
    "- def predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5394ded3c5ad5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***定义模拟环境 FakeEnv，用训练好的 EnsembleDynamicsModel 来预测下一状态和奖励：***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f9a322fb51a1b950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.489718500Z",
     "start_time": "2025-08-25T12:04:47.120331300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)  \n",
    "        # (num_network, n_states, mean)\n",
    "        ensemble_model_means[:, :, 1:] += obs  # 当前状态+预测的状态增量，变为下一状态\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        # 得出每个模型成员的预测结果并使用高斯采样\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(\n",
    "            size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        # 为每一个状态的下一步预测使用随机的模型成员\n",
    "        models_to_use = np.random.choice([i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        # batch_size中每个状态都随机采用了某个模型成员进行预测（相应的奖励以及下一个状态）\n",
    "        rewards, next_obs = samples[:, :1][0][0], samples[:, 1:][0]\n",
    "        return rewards, next_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ccf489c333380",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 修改部分:\n",
    "- def step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472abc39256deb3f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 经验回放池Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b18f891f816ac25f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.489718500Z",
     "start_time": "2025-08-25T12:04:47.128309200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            return self.return_all_samples()\n",
    "        else:\n",
    "            transitions = random.sample(self.buffer, batch_size)\n",
    "            state, action, reward, next_state, done = zip(*transitions)\n",
    "            return np.array(state), np.array(action), reward, np.array(next_state), done\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92b0b2bb67c9ac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MBPO 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1eb1e89a59b85181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.559975800Z",
     "start_time": "2025-08-25T12:04:47.304643100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MBPO:\n",
    "    def __init__(self, env, agent, fake_env, env_pool, model_pool,\n",
    "                 rollout_length, rollout_batch_size, real_ratio, num_episode):\n",
    "\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.fake_env = fake_env\n",
    "        self.env_pool = env_pool\n",
    "        self.model_pool = model_pool\n",
    "        self.rollout_length = rollout_length\n",
    "        self.rollout_batch_size = rollout_batch_size\n",
    "        self.real_ratio = real_ratio\n",
    "        self.num_episode = num_episode\n",
    "\n",
    "    def rollout_model(self):\n",
    "        observations, _, _, _, _ = self.env_pool.sample(self.rollout_batch_size)\n",
    "        for obs in observations:\n",
    "            for i in range(self.rollout_length):\n",
    "                action = self.agent.take_action(obs)\n",
    "                reward, next_obs = self.fake_env.step(obs, action)\n",
    "                self.model_pool.add(obs, action, reward, next_obs, False)\n",
    "                obs = next_obs\n",
    "\n",
    "    def update_agent(self, policy_train_batch_size=64):\n",
    "        env_batch_size = int(policy_train_batch_size * self.real_ratio)\n",
    "        model_batch_size = policy_train_batch_size - env_batch_size\n",
    "        for epoch in range(10):\n",
    "            env_obs, env_action, env_reward, env_next_obs, env_done = self.env_pool.sample(env_batch_size)\n",
    "            \n",
    "            if self.model_pool.size() > 0:  # 按照占比 “混合训练”\n",
    "                model_obs, model_action, model_reward, model_next_obs, model_done = self.model_pool.sample(\n",
    "                    model_batch_size)\n",
    "                obs = np.concatenate((env_obs, model_obs), axis=0)\n",
    "                action = np.concatenate((env_action, model_action), axis=0)\n",
    "                next_obs = np.concatenate((env_next_obs, model_next_obs), axis=0)\n",
    "                reward = np.concatenate((env_reward, model_reward), axis=0)\n",
    "                done = np.concatenate((env_done, model_done), axis=0)\n",
    "            else:  # 无环境模型采样数据，只用真实环境数据训练Agent\n",
    "                obs, action, next_obs, reward, done = env_obs, env_action, env_next_obs, env_reward, env_done\n",
    "                \n",
    "            transition_dict = {\n",
    "                'states': obs,\n",
    "                'actions': action,\n",
    "                'next_states': next_obs,\n",
    "                'rewards': reward,\n",
    "                'dones': done\n",
    "            }\n",
    "            self.agent.update(transition_dict)\n",
    "\n",
    "    def train_model(self):\n",
    "        obs, action, reward, next_obs, done = self.env_pool.return_all_samples()\n",
    "        inputs = np.concatenate((obs, action), axis=-1)\n",
    "        reward = np.array(reward)\n",
    "        labels = np.concatenate((np.reshape(reward, (reward.shape[0], -1)), next_obs - obs), axis=-1)\n",
    "        self.fake_env.model.train(inputs, labels)\n",
    "\n",
    "    def explore(self):\n",
    "        episode_return = 0\n",
    "        obs, info = self.env.reset()\n",
    "        done = False\n",
    "        truncated = False\n",
    "        while not (done or truncated):  # 任务失败或达到最大步数\n",
    "            action = self.agent.take_action(obs)\n",
    "            next_obs, reward, done, truncated, _  = self.env.step(action)\n",
    "            self.env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 随机探索采取数据\n",
    "        print('episode: 1, 初始随机动作采样return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episode - 1):\n",
    "            step = 0\n",
    "            episode_return = 0\n",
    "            obs, info = self.env.reset()\n",
    "            done = False\n",
    "            truncated = False\n",
    "            while not (done or truncated):  # 任务失败或达到最大步数\n",
    "                if step % 50 == 0:\n",
    "                    self.train_model()  # 每次迭代中每50步对 环境模型 进行训练\n",
    "                    self.rollout_model()  # 每次迭代中每50步进行 rollout 采样\n",
    "                action = self.agent.take_action(obs)\n",
    "                next_obs, reward, done, truncated, _  = self.env.step(action)\n",
    "                self.env_pool.add(obs, action, reward, next_obs, done)\n",
    "                obs = next_obs\n",
    "                episode_return += reward\n",
    "\n",
    "                self.update_agent()\n",
    "                step += 1\n",
    "            \n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4e0583d9a303e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 环境设置（'Pendulum-v1'）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ffdca1444ad74e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.559975800Z",
     "start_time": "2025-08-25T12:04:47.313813200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment spec: EnvSpec(id='Pendulum-v1', entry_point='gymnasium.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, disable_env_checker=False, kwargs={}, namespace=None, name='Pendulum', version=1, additional_wrappers=(), vector_entry_point=None)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)    # 设置 NumPy 的随机种子\n",
    "torch.manual_seed(0) # 设置 PyTorch CPU 随机种子\n",
    "torch.cuda.manual_seed_all(0) # 设置 PyTorch GPU 随机种子, 由于GPU并行性, 只能极大减小偏差\n",
    "\n",
    "env_name = 'Pendulum-v1'\n",
    "env = gym.make(env_name)\n",
    "env.reset(seed=0)   # 环境通常依赖于其他随机数生成器来初始化状态、进行探索(推荐位于以上随机之后)\n",
    "print(\"Environment spec:\", env.spec)\n",
    "\n",
    "buffer_size = 10000\n",
    "env_pool = ReplayBuffer(buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f84c439d79257",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 超参数设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "35798f69af04337f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:04:47.559975800Z",
     "start_time": "2025-08-25T12:04:47.324328800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "hidden_dim = 128\n",
    "action_dim = env.action_space.shape[0]  # 连续动作空间\n",
    "action_bound = env.action_space.high[0]  # 动作最大值\n",
    "# 智能体参数\n",
    "actor_lr = 5e-4\n",
    "critic_lr = 5e-3\n",
    "alpha_lr = 1e-3\n",
    "\n",
    "target_entropy = -env.action_space.shape[0] # 目标熵\n",
    "tau = 0.005  # 软更新参数\n",
    "gamma = 0.98\n",
    "\n",
    "agent = SACContinuous(state_dim, hidden_dim, action_dim, action_bound, actor_lr,\n",
    "            critic_lr, alpha_lr, target_entropy, tau, gamma, device)\n",
    "\n",
    "# 环境模型\n",
    "model = EnsembleDynamicsModel(state_dim, action_dim)\n",
    "fake_env = FakeEnv(model)\n",
    "\n",
    "rollout_batch_size = 1000\n",
    "rollout_length = 1  # 推演长度k,推荐更多尝试\n",
    "model_pool_size = rollout_batch_size * rollout_length\n",
    "model_pool = ReplayBuffer(model_pool_size)\n",
    "\n",
    "real_ratio = 0.5\n",
    "num_episodes = 30\n",
    "\n",
    "mbpo = MBPO(env, agent, fake_env, env_pool, model_pool, rollout_length,\n",
    "            rollout_batch_size, real_ratio, num_episodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7091394e402fe1c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 测试与训练:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b55e2a4088ef2186",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:33:30.271028500Z",
     "start_time": "2025-08-25T12:04:47.366201200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, 初始随机动作采样return: -1805\n",
      "episode: 2, return: -1340\n",
      "episode: 3, return: -1113\n",
      "episode: 4, return: -1218\n",
      "episode: 5, return: -1090\n",
      "episode: 6, return: -1663\n",
      "episode: 7, return: -1548\n",
      "episode: 8, return: -1726\n",
      "episode: 9, return: -1665\n",
      "episode: 10, return: -1668\n",
      "episode: 11, return: -1505\n",
      "episode: 12, return: -1263\n",
      "episode: 13, return: -1627\n",
      "episode: 14, return: -1320\n",
      "episode: 15, return: -1565\n",
      "episode: 16, return: -1521\n",
      "episode: 17, return: -1485\n",
      "episode: 18, return: -1587\n",
      "episode: 19, return: -1464\n",
      "episode: 20, return: -1187\n",
      "episode: 21, return: -887\n",
      "episode: 22, return: -766\n",
      "episode: 23, return: -250\n",
      "episode: 24, return: -287\n",
      "episode: 25, return: -120\n",
      "episode: 26, return: -247\n",
      "episode: 27, return: -123\n",
      "episode: 28, return: -1\n",
      "episode: 29, return: -114\n",
      "episode: 30, return: -126\n"
     ]
    }
   ],
   "source": [
    "return_list = mbpo.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b648621c1265955",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 绘图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ad2a55d451f00d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:33:30.287215100Z",
     "start_time": "2025-08-25T12:33:30.273027800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "episodes_list = list(range(len(return_list)))\n",
    "# 创建 DataFrame\n",
    "df1 = pd.DataFrame({'Episodes': episodes_list, 'Returns': return_list})\n",
    "# 保存为 CSV 文件\n",
    "df1.to_csv('MBPO_Pendulum-v1_returns_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee1aa04abfd1205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T12:41:37.946191Z",
     "start_time": "2025-08-25T12:41:36.884659300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Returns",
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "y": {
          "bdata": "WeKhCzY2nMCYMcvHKvKUwLTX3JA+ZZHAjF/x+MEIk8BOBA48gwiRwAN0dfLX/ZnAij/o5LQymMDX02t9gPuawGsq16tBBJrAkhRsqE4TmsDCCmgyIIeXwPVhkPaPvJPAQ+LbDlRsmcAGdHslFqCUwFDTUlbod5jAXYNgtg7El8DhzDXd7DaXwIR5daKEzpjAjSzj1EThlsA6Q5Y1goySwDRwk5FovYvAXNFmOoXyh8DPOgo6rF1vwH6YCZZu/HHAhUXqFjIUXsC1KByA4vBuwLmmQ7H41l7AQPFMG/fy9L943nwRuq5cwBo7V031uF/A",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "MBPO on Pendulum-v1"
        },
        "xaxis": {
         "title": {
          "text": "Episodes"
         }
        },
        "yaxis": {
         "title": {
          "text": "Returns"
         }
        }
       }
      },
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "df = pd.read_csv('MBPO_Pendulum-v1_returns_data.csv')  # 从 CSV 文件中读取数据\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['Episodes'], y=df['Returns'], mode='lines', name='Returns'))\n",
    "fig.update_layout(\n",
    "    title='MBPO on Pendulum-v1',\n",
    "    xaxis_title='Episodes',\n",
    "    yaxis_title='Returns',\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4238c3d210bbfb75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*相比 **无模型** 的强化学习算法，基于模型的方法 **MBPO** 在样本效率上要高\n",
    "虽然这里的效果不如 **PETS** 算法优秀，但是在许多更加复杂的环境中（如 Hopper 和 HalfCheetah） **MBPO** 的表现远远好于 **PETS** 算法*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
